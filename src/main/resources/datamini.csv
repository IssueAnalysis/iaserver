Summary,Issue key,Issue id,Parent id,Issue Type,Status,Project key,Project name,Project type,Project lead,Project description,Project url,Priority,Resolution,Assignee,Reporter,Creator,Created,Updated,Last Viewed,Resolved,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Component/s,Component/s,Component/s,Component/s,Component/s,Due Date,Votes,Labels,Labels,Description,Environment,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Original Estimate,Remaining Estimate,Time Spent,Work Ratio,Î£ Original Estimate,Î£ Remaining Estimate,Î£ Time Spent,Security Level,Outward issue link (Blocker),Outward issue link (Blocker),Outward issue link (Blocker),Outward issue link (Blocker),Outward issue link (Blocker),Outward issue link (Container),Outward issue link (Duplicate),Outward issue link (Incorporates),Outward issue link (Incorporates),Outward issue link (Incorporates),Outward issue link (Incorporates),Outward issue link (Problem/Incident),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Regression),Outward issue link (Regression),Outward issue link (Required),Outward issue link (Supercedes),Outward issue link (Supercedes),Outward issue link (Supercedes),Outward issue link (Supercedes),Outward issue link (dependent),Outward issue link (dependent),Outward issue link (dependent),Outward issue link (dependent),Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Custom field (Attachment count),Custom field (Blog - New Blog Administrators),Custom field (Blog - New Blog PMC),Custom field (Blog - Write access),Custom field (Blog Administrator?),Custom field (Blogs - Admin for blog),Custom field (Blogs - Email Address),Custom field (Blogs - Existing Blog Access Level),Custom field (Blogs - Existing Blog Name),Custom field (Blogs - New Blog Write Access),Custom field (Blogs - Username),Custom field (Bug Category),Custom field (Bugzilla - Email Notification Address),Custom field (Bugzilla - List of usernames),Custom field (Bugzilla - PMC Name),Custom field (Bugzilla - Project Name),Custom field (Bugzilla Id),Custom field (Change Category),Custom field (Complexity),Custom field (Date of First Response),Custom field (Discovered By),Custom field (Docs Text),Custom field (Enable Automatic Patch Review),Custom field (Epic Colour),Custom field (Epic Link),Custom field (Epic Name),Custom field (Epic Status),Custom field (Existing GitBox Approval),Custom field (External issue ID),Custom field (External issue URL),Custom field (Flags),Custom field (Flags),Custom field (Git Notification Mailing List),Custom field (Git Repository Import Path),Custom field (Git Repository Name),Custom field (Git Repository Type),Custom field (GitHub Options),Custom field (Github Integration),Custom field (Github Integrations - Other),Custom field (Global Rank),Custom field (Hadoop Flags),Custom field (Hadoop Flags),Custom field (INFRA - Subversion Repository Path),Custom field (Initial Confluence Contributors),Custom field (Last public comment date),Custom field (Machine Readable Info),Custom field (New-TLP-TLPName),Custom field (Priority),Custom field (Project),Custom field (Protected Branch),Custom field (Rank),Custom field (Rank (Obsolete)),Custom field (Release Note),Custom field (Severity),Custom field (Severity),Custom field (Source Control Link),Custom field (Space Description),Custom field (Space Key),Custom field (Space Name),Custom field (Tags),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Test and Documentation Plan),Custom field (Testcase included),Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment
Crashing bugs in NameNode when using a valid configuration for `dfs.namenode.audit.loggers`,HDFS-15124,13279452,,Bug,Patch Available,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Critical,,,ctest.team,ctest.team,14/01/2020 22:34,17/01/2020 02:12,18/01/2020 01:02,,2.10.0,,,,,,,,,,,,namenode,,,,,,0,,,"I am using Hadoop-2.10.0.The configuration parameter `dfs.namenode.audit.loggers` allows `default` (which is the default value) and `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`.When I use `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`, namenode will not be started successfully because of an `InstantiationException` thrown from `org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers`.Â The root cause is that while initializing namenode, `initAuditLoggers` will be called and it will try to call the default constructor of `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger` which doesn't have a default constructor. Thus the `InstantiationException` exception is thrown.Â *Symptom**$ ./start-dfs.sh*{code:java}2019-12-18 14:05:20,670 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.java.lang.RuntimeException: java.lang.InstantiationException: org.apache.hadoop.hdfs.server.namenode.top.TopAuditLoggerat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1024)at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:858)at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:677)at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:674)at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:736)at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:961)at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:940)at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1714)at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1782)Caused by: java.lang.InstantiationException: org.apache.hadoop.hdfs.server.namenode.top.TopAuditLoggerat java.lang.Class.newInstance(Class.java:427)at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1017)...8 moreCaused by: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger.<init>()at java.lang.Class.getConstructor0(Class.java:3082)at java.lang.Class.newInstance(Class.java:412)... 9 more{code}Â Â *Detailed Root Cause*There is no default constructor in `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`:Â {code:java}/**  * An {@link AuditLogger} that sends logged data directly to the metrics  * systems. It is used when the top service is used directly by the name node  */ @InterfaceAudience.Private public class TopAuditLogger implements AuditLogger {       public static finalLogger LOG = LoggerFactory.getLogger(TopAuditLogger.class);   private final TopMetrics topMetrics;   public TopAuditLogger(TopMetrics topMetrics) {    Preconditions.checkNotNull(topMetrics, ""Cannot init with a null "" +         ""TopMetrics"");    this.topMetrics = topMetrics;   }  @Override  public void initialize(Configuration conf) {   }{code}As long as the configuration parameter `dfs.namenode.audit.loggers` is set to `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`, `initAuditLoggers` will try to call its default constructor to make a new instance:Â {code:java}private List<AuditLogger> initAuditLoggers(Configuration conf) {Â  // Initialize the custom access loggers if configured.Â  Collection<String> alClasses =Â  Â  Â  conf.getTrimmedStringCollection(DFS_NAMENODE_AUDIT_LOGGERS_KEY);Â  List<AuditLogger> auditLoggers = Lists.newArrayList();Â  if (alClasses != null && !alClasses.isEmpty()) {Â  Â  for (String className : alClasses) {Â  Â  Â  try {Â  Â  Â  Â  AuditLogger logger;Â  Â  Â  Â  if (DFS_NAMENODE_DEFAULT_AUDIT_LOGGER_NAME.equals(className)) {Â  Â  Â  Â  Â  logger = new DefaultAuditLogger();Â  Â  Â  Â  } else {Â  Â  Â  Â  Â  logger = (AuditLogger) Class.forName(className).newInstance();Â  Â  Â  Â  }Â  Â  Â  Â  logger.initialize(conf);Â  Â  Â  Â  auditLoggers.add(logger);Â  Â  Â  } catch (RuntimeException re) {Â  Â  Â  Â  throw re;Â  Â  Â  } catch (Exception e) {Â  Â  Â  Â  throw new RuntimeException(e);Â  Â  Â  }Â  Â  }Â  }{code}`initAuditLoggers` tries to call the default constructor to make a new instance in:{code:java}logger = (AuditLogger) Class.forName(className).newInstance();{code}This is very different from the default configuration, `default`, which implements a default constructor so the default is fine.Â *How To Reproduce*Â The version of Hadoop: 2.10.0 # Set the value of configuration parameter `dfs.namenode.audit.loggers` to `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger` in ""hdfs-site.xml""(the default value is `default`) # Start the namenode by running ""start-dfs.sh"" # The namenode will not be started successfully.{code:java}<property>Â Â <name>dfs.namenode.audit.loggers</name>Â Â <value>org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger</value>Â Â <description>Â Â Â Â List of classes implementing audit loggers that will receive audit events.Â Â Â Â These should be implementations of org.apache.hadoop.hdfs.server.namenode.AuditLogger.Â Â Â Â The special value ""default"" can be used to reference the default auditÂ Â Â Â logger, which uses the configured log system. Installing custom audit loggersÂ Â Â Â may affect the performance and stability of the NameNode. Refer to the customÂ Â Â Â logger's documentation for more details.Â Â </description></property>{code}Â *How To Fix*Add a default constructor for `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`.I wrote a patch to add a default constructor forÂ TopAuditLogger.",,ctest.team,elgoiri,weichiu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15/Jan/20 02:25;ctest.team;HDFS-15124.000.patch;https://issues.apache.org/jira/secure/attachment/12990931/HDFS-15124.000.patch,16/Jan/20 17:25;ctest.team;HDFS-15124.001.patch;https://issues.apache.org/jira/secure/attachment/12991162/HDFS-15124.001.patch,16/Jan/20 22:56;ctest.team;HDFS-15124.002.patch;https://issues.apache.org/jira/secure/attachment/12991181/HDFS-15124.002.patch,,,,,,,,,,,,,,,,,,,,,,3,,,,,,,,,,,,,,,,,,,42:12.5,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Fri Jan 17 02:12:05 UTC 2020,,,,,,0|z0aig0:,9.22337E+18,,,,,,,,,,,,,,,,,,"14/Jan/20 22:42;weichiu;You shouldn't need to add TopAuditLogger to auditlogger configuration. As long as dfs.namenode.top.enabled is true (default), it is added.","14/Jan/20 23:16;ctest.team;[~weichiu] Thank you for your reply!Yes. The default value can also addÂ TopAuditLogger, but most users don't read the src code and don't know it.If the users want to useÂ TopAuditLogger and they directly set it toÂ TopAuditLogger (without understanding the src code), then the namenode will crash.I wrote a patch to add the default constructor for theÂ TopAuditLogger which I think can make this part more robust.","14/Jan/20 23:39;elgoiri;In addition to the constructor, the exception for this case is a little verbose and not intuitive.Is there a way we can improve that too?One can follow the full stack trace but it is buried...","15/Jan/20 03:01;ctest.team;[~elgoiri]Â Thank you for your reply and this is a good point! How about catching InstantiationException in `initAuditLoggers(Configuration conf)`It will look like:{code:java}private List<AuditLogger> initAuditLoggers(Configuration conf) {  // Initialize the custom access loggers if configured.  Collection<String> alClasses =      conf.getTrimmedStringCollection(DFS_NAMENODE_AUDIT_LOGGERS_KEY);  List<AuditLogger> auditLoggers = Lists.newArrayList();  if (alClasses != null && !alClasses.isEmpty()) {    for (String className : alClasses) {      try {        AuditLogger logger;        if (DFS_NAMENODE_DEFAULT_AUDIT_LOGGER_NAME.equals(className)) {          logger = new DefaultAuditLogger();        } else {          logger = (AuditLogger) Class.forName(className).newInstance();        }        logger.initialize(conf);        auditLoggers.add(logger);      } catch (InstantiationException e) {        LOG.error(""Instantiation error for "" + className);        throw new RuntimeException(e);      } catch (RuntimeException re) {        throw re;      } catch (Exception e) {        throw new RuntimeException(e);      }    }  }{code}The log error message can be refined. I can upload another patch for this if this is the right way to do it.","15/Jan/20 05:30;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 45s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 24m 26s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  7s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 34s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 12s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 20s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 35s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 25s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 10s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 13s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}115m 21s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}180m 15s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.server.namenode.TestRedudantBlocks |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:c44943d1fc3 || JIRA Issue | HDFS-15124 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12990931/HDFS-15124.000.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 778f53fdcbb8 4.15.0-65-generic #74-Ubuntu SMP Tue Sep 17 17:06:04 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / c36f09d || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_232 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28675/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28675/testReport/ || Max. process+thread count | 3894 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28675/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.","15/Jan/20 18:37;elgoiri;Thanks [~ctest.team] for the proposal, yes, I think it makes sense.Just use the logger style with {}.",15/Jan/20 19:45;weichiu;Please make sure you don't add TopAuditLogger twice by setting dfs.namenode.top.enabled to TopAuditLogger.,16/Jan/20 02:05;ctest.team;[~elgoiri] [~weichiu] Sure. I will upload a new patch to do that. Thank you for your suggestions.,"16/Jan/20 17:32;ctest.team;I uploaded a new patch to do all these changes.[~elgoiri]Â I am sorry I didn't use {} style for the LOG in FSNamesystem.java because inÂ FSNamesystem.java the LOG is `org.apache.commons.logging.Log` instead of `org.slf4j.Logger`. TheÂ `org.apache.commons.logging.Log` doesn't support{code:java}LOG.error(""xxx {}"", ""yyy""){code}Please let me know if anything else needed. Thank you!","16/Jan/20 17:48;elgoiri;FSNameSystem seems to be using logger, right?https://github.com/apache/hadoop/blob/a0ff42d7612e744e0bf88aa14078ea3ab6bcce49/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java#L373It was done by HDFS-12552.","16/Jan/20 19:08;ctest.team;[~elgoiri] Sorry that I was using hadoop-2.10.0 and theÂ FSNameSystem was usingÂ {code:java}public static final Log LOG = LogFactory.getLog(FSNamesystem.class);{code}[https://github.com/apache/hadoop/blob/e2f1f118e465e787d8567dfa6e2f3b72a0eb9194/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java#L328]It seems that 3.x.x is usingÂ org.slf4j.Logger but 2.x.x is usingÂ org.apache.commons.logging.Log for FSNanesystem.java.I will write another patch for trunk and upload it again. Thank you for pointing this out!","16/Jan/20 20:49;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 51s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 55s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  4s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  8s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 29s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 19s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 15s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} || {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 41s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 1 new + 166 unchanged - 0 fixed = 167 total (was 166) {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  5s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 33s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 42s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 24s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}134m  8s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}198m 52s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDecommission ||   | hadoop.hdfs.server.namenode.snapshot.TestSnapshot ||   | hadoop.hdfs.server.namenode.TestINodeAttributeProvider ||   | hadoop.hdfs.TestDatanodeRegistration ||   | hadoop.hdfs.server.namenode.TestRedudantBlocks ||   | hadoop.hdfs.server.namenode.TestFSImage ||   | hadoop.hdfs.server.namenode.TestFsck ||   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:c44943d1fc3 || JIRA Issue | HDFS-15124 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12991162/HDFS-15124.001.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 8fac4d4b27be 4.15.0-74-generic #84-Ubuntu SMP Thu Dec 19 08:06:28 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / a0ff42d || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_232 || findbugs | v3.1.0-RC1 || checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28684/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28684/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28684/testReport/ || Max. process+thread count | 2649 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28684/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",17/Jan/20 01:19;ctest.team;Uploaded one new patch for trunk.,"17/Jan/20 02:12;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 41s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m 23s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  6s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 13s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 11s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 28s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 16s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} || {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 41s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 1 new + 166 unchanged - 0 fixed = 167 total (was 166) {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 13s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 25s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 45s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 24s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}123m 13s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 32s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}191m 22s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDeadNodeDetection ||   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks ||   | hadoop.hdfs.server.namenode.TestRedudantBlocks ||   | hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:c44943d1fc3 || JIRA Issue | HDFS-15124 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12991181/HDFS-15124.002.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 0fb99bc6d2d0 4.15.0-74-generic #84-Ubuntu SMP Thu Dec 19 08:06:28 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 263413e || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_232 || findbugs | v3.1.0-RC1 || checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28687/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28687/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28687/testReport/ || Max. process+thread count | 2570 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28687/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RBF: Print stacktrace when DFSRouter fails to fetch/parse JMX output from NameNode,HDFS-15100,13278086,13241304,Sub-task,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Major,Fixed,aajisaka,aajisaka,aajisaka,08/01/2020 08:11,10/01/2020 04:31,18/01/2020 01:03,10/01/2020 04:18,,,,,,3.3.0,,,,,,,rbf,,,,,,0,supportability,,"When DFSRouter fails to fetch or parse JMX output from NameNode, it prints only the error message. Therefore we had to modify the source code to print the stacktrace of the exception to find the root cause.",,aajisaka,ayushsaxena,elgoiri,hudson,John Smith,tasanuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,01:15.6,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Fri Jan 10 04:31:43 UTC 2020,,,,,,0|z0aacg:,9.22337E+18,,,,,,,,,3.3.0,,,,,,,,,"08/Jan/20 14:01;elgoiri;Can you show the output of the trace before and after?I personally prefer single line messages for known exceptions. ","09/Jan/20 02:29;aajisaka;Thanks [~inigoiri] for your comment.This is the output: https://gist.github.com/aajisaka/33699d0ef825cf587e0bb4a5575c1939This change is for the errors that we have to find the root cause of and fix, so I'd like to see the detailed information.","09/Jan/20 17:47;elgoiri;A little verbose but I guess that's what we need, let me comment in the PR.","10/Jan/20 04:18;tasanuma;Committed to trunk. Thanks for your contribution, [~aajisaka]. Thanks for your review, [~elgoiri].","10/Jan/20 04:31;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17842 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17842/])HDFS-15100. RBF: Print stacktrace when DFSRouter fails to fetch/parse (tasanuma: rev 0315ef844862ee863d646b562ba6d8889876ffa9)* (edit) hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/FederationUtil.java",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DataNode.DataTransfer thread should catch all the expception and log it.,HDFS-15074,13275454,,Improvement,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Major,Fixed,hemanthboyina,surendrasingh,surendrasingh,19/12/2019 09:47,29/12/2019 06:06,18/01/2020 01:03,29/12/2019 06:02,3.1.1,,,,,3.1.4,3.2.2,3.3.0,,,,,datanode,,,,,,0,,,"Some time If this thread is throwing exception other than IOException, will not be able to trash it.",,elgoiri,hemanthboyina,hudson,surendrasingh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,23/Dec/19 17:32;hemanthboyina;HDFS-15074.001.patch;https://issues.apache.org/jira/secure/attachment/12989389/HDFS-15074.001.patch,25/Dec/19 17:52;hemanthboyina;HDFS-15074.002.patch;https://issues.apache.org/jira/secure/attachment/12989464/HDFS-15074.002.patch,,,,,,,,,,,,,,,,,,,,,,,2,,,,,,,,,,,,,,,,,,,32:59.1,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Sun Dec 29 06:06:08 UTC 2019,,,,,,0|z09u48:,9.22337E+18,,,,,,,,,,,,,,,,,,"23/Dec/19 17:32;hemanthboyina;attached patch , please review","23/Dec/19 20:38;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 53s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 33s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  5s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 28s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 12s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 24s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 20s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 13s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}115m 42s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}177m 41s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDatanodeRegistration ||   | hadoop.hdfs.server.namenode.TestRedudantBlocks ||   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots ||   | hadoop.hdfs.TestFileChecksumCompositeCrc |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:c44943d1fc3 || JIRA Issue | HDFS-15074 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12989389/HDFS-15074.001.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux c2fd4ae01a33 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 34ff7db || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_232 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28559/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28559/testReport/ || Max. process+thread count | 2887 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28559/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.","25/Dec/19 15:56;surendrasingh;[~hemanthboyina], minor comment.Just log the exception like this{code:java}LOG.error(""Failed to transfer block "" + b, t); {code}","25/Dec/19 18:03;hemanthboyina;thanks for the review [~surendrasingh]Â .Â Â updated the patch , please review .Â ","25/Dec/19 20:56;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 57s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 30s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  4s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 39s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 16s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 12s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 29s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 19s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}103m 43s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}166m  2s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestFileChecksum ||   | hadoop.hdfs.TestDeadNodeDetection ||   | hadoop.hdfs.TestDatanodeRegistration ||   | hadoop.hdfs.server.namenode.TestRedudantBlocks ||   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots ||   | hadoop.hdfs.TestFileChecksumCompositeCrc ||   | hadoop.hdfs.TestRollingUpgrade |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:c44943d1fc3 || JIRA Issue | HDFS-15074 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12989464/HDFS-15074.002.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 8d59a8e92c65 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 300505c || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_232 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28569/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28569/testReport/ || Max. process+thread count | 2963 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28569/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",27/Dec/19 06:57;surendrasingh;+1,"29/Dec/19 06:02;surendrasingh;Committed to trunk, branch-3.2, branch-3.1","29/Dec/19 06:06;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17800 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17800/])HDFS-15074. DataNode.DataTransfer thread should catch all the expception (surendralilhore: rev ee51eadda01e02ac5759ca19756f6f961c8eb0cd)* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Duplicated: Crashing bugs in NameNode when using a valid configuration for `dfs.namenode.audit.loggers`,HDFS-15070,13275337,,Bug,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Critical,Duplicate,,XudongSun,XudongSun,18/12/2019 21:26,14/01/2020 23:04,18/01/2020 01:03,14/01/2020 23:03,2.10.0,,,,,,,,,,,,namenode,,,,,,0,,,"I am using Hadoop-2.10.0.The configuration parameter `dfs.namenode.audit.loggers` allows `default` (which is the default value) and `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`.When I use `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`, namenode will not be started successfully because of an `InstantiationException` thrown from `org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers`.Â The root cause is that while initializing namenode, `initAuditLoggers` will be called and it will try to call the default constructor of `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger` which doesn't have a default constructor. Thus the `InstantiationException` exception is thrown.Â *Symptom**$ ./start-dfs.sh*Â {code:java}2019-12-18 14:05:20,670 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.java.lang.RuntimeException: java.lang.InstantiationException: org.apache.hadoop.hdfs.server.namenode.top.TopAuditLoggerat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1024)at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:858)at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:677)at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:674)at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:736)at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:961)at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:940)at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1714)at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1782)Caused by: java.lang.InstantiationException: org.apache.hadoop.hdfs.server.namenode.top.TopAuditLoggerat java.lang.Class.newInstance(Class.java:427)at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1017)... 8 moreCaused by: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger.<init>()at java.lang.Class.getConstructor0(Class.java:3082)at java.lang.Class.newInstance(Class.java:412)... 9 more{code}Â Â *Detailed Root Cause*There is no default constructor in `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`:{code:java}/**  * An {@link AuditLogger} that sends logged data directly to the metrics  * systems. It is used when the top service is used directly by the name node  */ @InterfaceAudience.Private public class TopAuditLogger implements AuditLogger {       public static finalLogger LOG = LoggerFactory.getLogger(TopAuditLogger.class);   private final TopMetrics topMetrics;   public TopAuditLogger(TopMetrics topMetrics) {    Preconditions.checkNotNull(topMetrics, ""Cannot init with a null "" +         ""TopMetrics"");    this.topMetrics = topMetrics;   }  @Override  public void initialize(Configuration conf) {   }{code}As long as the configuration parameter `dfs.namenode.audit.loggers` is set to `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`, `initAuditLoggers` will try to call its default constructor to make a new instance:{code:java}private List<AuditLogger> initAuditLoggers(Configuration conf) {  // Initialize the custom access loggers if configured.  Collection<String> alClasses =      conf.getTrimmedStringCollection(DFS_NAMENODE_AUDIT_LOGGERS_KEY);  List<AuditLogger> auditLoggers = Lists.newArrayList();  if (alClasses != null && !alClasses.isEmpty()) {    for (String className : alClasses) {      try {        AuditLogger logger;        if (DFS_NAMENODE_DEFAULT_AUDIT_LOGGER_NAME.equals(className)) {          logger = new DefaultAuditLogger();        } else {          logger = (AuditLogger) Class.forName(className).newInstance();        }        logger.initialize(conf);        auditLoggers.add(logger);      } catch (RuntimeException re) {        throw re;      } catch (Exception e) {        throw new RuntimeException(e);      }    }  }{code}`initAuditLoggers` tries to call the default constructor to make a new instance in:{code:java}logger = (AuditLogger) Class.forName(className).newInstance();{code}This is very different from the default configuration, `default`, which implements a default constructor so the default is fine.Â *How To Reproduce*Â The version of Hadoop: 2.10.0 # Set the value of configuration parameter `dfs.namenode.audit.loggers` to `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger` in ""hdfs-site.xml""(the default value is `default`) # Start the namenode by running ""start-dfs.sh"" # The namenode will not be started successfully. Â {code:java}<property>Â Â <name>dfs.namenode.audit.loggers</name>Â Â <value>org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger</value>Â Â <description>Â Â Â Â List of classes implementing audit loggers that will receive audit events.Â Â Â Â These should be implementations of org.apache.hadoop.hdfs.server.namenode.AuditLogger.Â Â Â Â The special value ""default"" can be used to reference the default auditÂ Â Â Â logger, which uses the configured log system. Installing custom audit loggersÂ Â Â Â may affect the performance and stability of the NameNode. Refer to the customÂ Â Â Â logger's documentation for more details.Â Â </description></property>{code}Â *How To Fix*Add a default constructor for `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`",,csun,elgoiri,tianyin,XudongSun,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,26:34.0,,,,,,0|z09te8:,9.22337E+18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add LOG when sendIBRs failed,HDFS-15062,13274716,,Improvement,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Major,Fixed,ferhui,ferhui,ferhui,16/12/2019 09:30,20/12/2019 19:28,18/01/2020 01:03,20/12/2019 19:28,3.0.3,3.1.3,3.2.1,,,3.3.0,,,,,,,datanode,,,,,,0,,,"{code}  /** Send IBRs to namenode. */  void sendIBRs(DatanodeProtocol namenode, DatanodeRegistration registration,      String bpid, String nnRpcLatencySuffix) throws IOException {    // Generate a list of the pending reports for each storage under the lock    final StorageReceivedDeletedBlocks[] reports = generateIBRs();    if (reports.length == 0) {      // Nothing new to report.      return;    }    // Send incremental block reports to the Namenode outside the lock    if (LOG.isDebugEnabled()) {      LOG.debug(""call blockReceivedAndDeleted: "" + Arrays.toString(reports));    }    boolean success = false;    final long startTime = monotonicNow();    try {      namenode.blockReceivedAndDeleted(registration, bpid, reports);      success = true;    } finally {      if (success) {        dnMetrics.addIncrementalBlockReport(monotonicNow() - startTime,            nnRpcLatencySuffix);        lastIBR = startTime;      } else {        // If we didn't succeed in sending the report, put all of the        // blocks back onto our queue, but only in the case where we        // didn't put something newer in the meantime.        putMissing(reports);      }    }  }{code}When call namenode.blockReceivedAndDelete failed, will put reports to pendingIBRs. Maybe we should add log for failed case. It is helpful for trouble shooting",,ayushtkn,ebadger,elgoiri,ferhui,hexiaoqiao,hudson,weichiu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,16/Dec/19 09:35;ferhui;HDFS-15062.001.patch;https://issues.apache.org/jira/secure/attachment/12988913/HDFS-15062.001.patch,17/Dec/19 00:52;ferhui;HDFS-15062.002.patch;https://issues.apache.org/jira/secure/attachment/12988957/HDFS-15062.002.patch,19/Dec/19 01:16;ferhui;HDFS-15062.003.patch;https://issues.apache.org/jira/secure/attachment/12989151/HDFS-15062.003.patch,,,,,,,,,,,,,,,,,,,,,,3,,,,,,,,,,,,,,,,,,,39:40.8,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,Reviewed,,,,Fri Dec 20 19:27:38 UTC 2019,,,,,,0|z09pk8:,9.22337E+18,,,,,,,,,,,,,,,,,,16/Dec/19 12:15;ferhui;[~weichiu] [~ayushtkn] Could you please take a look ? Thanks,"16/Dec/19 13:39;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 43s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 21s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 38s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 13s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 11s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 27s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 17s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}103m 12s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 32s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}164m 52s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDeadNodeDetection ||   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:e573ea49085 || JIRA Issue | HDFS-15062 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12988913/HDFS-15062.001.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 7c1e2b89cbc7 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / dc6cf17 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28532/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28532/testReport/ || Max. process+thread count | 2778 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28532/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.","16/Dec/19 18:14;elgoiri;Not that it makes much of a difference with warn and this setting but it makes sense to use the logger format:{code}LOG.warn(""Failed to call blockReceivedAndDeleted: {}"", Arrays.toString(reports));{code}","17/Dec/19 00:52;ferhui;[~elgoiri] Thanks for your comments!Upload v002 patch",17/Dec/19 01:43;elgoiri;+1 on  [^HDFS-15062.002.patch].,"17/Dec/19 03:45;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 42s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 17s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 24s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 12s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 34s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 20s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  9s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}102m 44s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}164m 20s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDeadNodeDetection |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:e573ea49085 || JIRA Issue | HDFS-15062 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12988957/HDFS-15062.002.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 68f1356b8742 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 578bd10 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28535/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28535/testReport/ || Max. process+thread count | 2767 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28535/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",17/Dec/19 16:17;ayushtkn;v002 LGTM +1,18/Dec/19 04:23;weichiu;What's the typical reason for failing to send IBRs? Time outs? I'm wondering if logging the duration of the call can be useful too.,"18/Dec/19 05:21;ferhui;[~weichiu] Now didn't see failing. I found that sending IBRs was delayed because of handling invalid blocks.I think adding log is helpful for quick trouble shooting","18/Dec/19 06:12;hexiaoqiao;It seems very similar to HDFS-14997, maybe it could solve this issue. FYI.","18/Dec/19 15:44;ferhui;[~hexiaoqiao] Thanks for reminding me. HDFS-14997 is great work, it could resolve the problem that sending IBRs was delayed.This JIRA just adds key logs for quick trouble shooting.","18/Dec/19 18:08;elgoiri;[~weichiu] was also bringing up if we needed to add more information to the log message.He proposed the duration but maybe there are other things too.[~ferhui], just give it a thought to see if we should add more info.","19/Dec/19 01:18;ferhui;[~weichiu] [~elgoiri]I think adding more info is good.Upload v003 patch add nnId and duration info","19/Dec/19 03:51;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 32s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 16s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  6s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 30s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  6s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 16s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 35s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 17s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  8s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 18s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red} 91m 12s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}148m 35s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDeadNodeDetection ||   | hadoop.hdfs.TestMultipleNNPortQOP ||   | hadoop.hdfs.TestReconstructStripedFile |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:e573ea49085 || JIRA Issue | HDFS-15062 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12989151/HDFS-15062.003.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 88a4ee862d58 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 7b93575 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28542/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28542/testReport/ || Max. process+thread count | 3975 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28542/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",19/Dec/19 04:02;weichiu;LGTM,"19/Dec/19 17:41;elgoiri;The failed unit tests are unrelated, updating my vote and committing shortly.+1 on  [^HDFS-15062.003.patch]","19/Dec/19 17:49;elgoiri;Thanks [~ferhui] for the patch and [~weichiu] and [~ayushtkn] for the reviews.Pushed to trunk, branch-3.2, branch-3.1, and branch-3.0.","19/Dec/19 18:04;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17779 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17779/])HDFS-15062. Add LOG when sendIBRs failed. Contributed by Fei Hui. (inigoiri: rev 52d7b745c6d95e799542d6409dac30d0418ce8a8)* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/IncrementalBlockReportManager.java",20/Dec/19 19:03;ebadger;This patch breaks branch-3.2 and branch-3.1 compilation. Remember that you always need to compile the code on each branch before you merge. ,"20/Dec/19 19:23;ebadger;I have reverted this patch from branch-3.2 and branch-3.1. I didn't bother with branch-3.0, since that branch is no longer active. ","20/Dec/19 19:27;elgoiri;My bad, logger format...Reverted it from 3.0 just for cleanness.I'll close it as is with just 3.3 as target.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Optimize log information when DFSInputStream meet CannotObtainBlockLengthException,HDFS-15050,13273879,,Improvement,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Major,Fixed,hexiaoqiao,hexiaoqiao,hexiaoqiao,11/12/2019 13:17,12/12/2019 11:26,18/01/2020 01:03,12/12/2019 10:26,,,,,,2.10.1,2.9.3,3.1.4,3.2.2,3.3.0,,,dfsclient,,,,,,0,,,"We could not identify which file it belongs easily when DFSInputStream meet CannotObtainBlockLengthException, as the following exception log. Just suggest to log file path string when we meet CannotObtainBlockLengthException.{code:java}Caused by: java.io.IOException: Cannot obtain block length for LocatedBlock{BP-***:blk_***_***; getBlockSize()=690504; corrupt=false; offset=1811939328; locs=[DatanodeInfoWithStorage[*:50010,DS-2bcadcc4-458a-45c6-a91b-8461bf7cdd71,DISK], DatanodeInfoWithStorage[*:50010,DS-8f2bb259-ecb2-4839-8769-4a0523360d58,DISK], DatanodeInfoWithStorage[*:50010,DS-69f4de6f-2428-42ff-9486-98c2544b1ada,DISK]]}	at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:402)	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:345)	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:280)	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:272)	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1664)	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:304)	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:300)	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:300)	at org.apache.hadoop.fs.FilterFileSystem.open(FilterFileSystem.java:161)	at org.apache.hadoop.fs.viewfs.ChRootedFileSystem.open(ChRootedFileSystem.java:266)	at org.apache.hadoop.fs.viewfs.ViewFileSystem.open(ViewFileSystem.java:481)	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:828)	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)	at org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.<init>(CombineHiveRecordReader.java:65)	... 16 more{code}",,hexiaoqiao,hudson,weichiu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11/Dec/19 13:18;hexiaoqiao;HDFS-15050.001.patch;https://issues.apache.org/jira/secure/attachment/12988539/HDFS-15050.001.patch,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,16:07.8,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Thu Dec 12 10:38:47 UTC 2019,,,,,,0|z09ke8:,9.22337E+18,,,,,,,,,,,,,,,,,,11/Dec/19 13:20;hexiaoqiao;submit init patch with minor exception changes.,"11/Dec/19 14:16;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 26s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 16s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 26s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 54s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 55s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 34s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 41s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 30s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  1s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 29s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 55s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 29s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black} 55m 19s{color} | {color:black} {color} |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:104ccca9169 || JIRA Issue | HDFS-15050 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12988539/HDFS-15050.001.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 8fede6446889 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / c2e9783 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28503/testReport/ || Max. process+thread count | 420 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs-client U: hadoop-hdfs-project/hadoop-hdfs-client || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28503/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",11/Dec/19 16:43;weichiu;+1,12/Dec/19 10:26;weichiu;Thanks [~hexiaoqiao] for contributing the patch. I've committed the patch to trunk branch-3.2 and branch-3.1.,"12/Dec/19 10:38;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17755 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17755/])HDFS-15050. Optimize log information when DFSInputStream meet (weichiu: rev 0e28cd8f63615dddded2f1183f27efb5c2aaf6aa)* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/CannotObtainBlockLengthException.java* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DataStreamer#createBlockOutputStream() should log exception in warn.,HDFS-15045,13273561,,Bug,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Major,Fixed,Sushma_28,surendrasingh,surendrasingh,10/12/2019 09:08,11/12/2019 03:39,18/01/2020 01:03,11/12/2019 03:27,3.1.1,,,,,3.3.0,,,,,,,dfsclient,,,,,,0,,,"{code:java}} catch (IOException ie) {        if (!errorState.isRestartingNode()) {          LOG.info(""Exception in createBlockOutputStream "" + this, ie);        } {code}",,elgoiri,hudson,surendrasingh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10/Dec/19 14:57;Sushma_28;HDFS-15045.001.patch;https://issues.apache.org/jira/secure/attachment/12988433/HDFS-15045.001.patch,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,23:44.5,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Wed Dec 11 03:39:36 UTC 2019,,,,,,0|z09ifk:,9.22337E+18,,,,,,,,,,,,,,,,,,"10/Dec/19 09:14;surendrasingh;Some time client side only warn log will be enabled, so user will not be able to get the reson for pipline failure..{code:java}2019-12-09 21:33:50,214 INFO hdfs.DataStreamer: Exception in createBlockOutputStream blk_1088983977_15246062java.net.BindException: Cannot assign requested address at sun.nio.ch.Net.connect0(Native Method) at sun.nio.ch.Net.connect(Net.java:454) at sun.nio.ch.Net.connect(Net.java:446) at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648) at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192) at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) at org.apache.hadoop.hdfs.DataStreamer.createSocketForPipeline(DataStreamer.java:255) at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1789) at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1743) at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:718){code}","10/Dec/19 18:21;surendrasingh;+1, will wait for build.","10/Dec/19 19:23;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 42s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 22m 17s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 25s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  3m  5s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 12s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 29s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 41s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m  5s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 21s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 29s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m  3s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black} 53m  0s{color} | {color:black} {color} |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:104ccca9169 || JIRA Issue | HDFS-15045 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12988433/HDFS-15045.001.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux cb6472647629 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 875a3e9 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28494/testReport/ || Max. process+thread count | 307 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs-client U: hadoop-hdfs-project/hadoop-hdfs-client || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28494/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.","11/Dec/19 03:27;surendrasingh;Committed to trunk.Thanks [~Sushma_28]Â  for contribution.","11/Dec/19 03:39;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17750 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17750/])HDFS-15045. DataStreamer#createBlockOutputStream() should log exception (surendralilhore: rev c2e9783d5f236015f2ad826fcbad061e2118e454)* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Dynamometer] Show the line of audit log when parsing it unsuccessfully,HDFS-15044,13273542,13215847,Sub-task,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Major,Fixed,tasanuma,tasanuma,tasanuma,10/12/2019 07:44,13/12/2019 00:28,18/01/2020 01:03,12/12/2019 15:51,,,,,,3.3.0,,,,,,,tools,,,,,,0,,,,,aajisaka,hudson,tasanuma,xkrogen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,51:00.0,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Fri Dec 13 00:28:39 UTC 2019,,,,,,0|z09ibc:,9.22337E+18,,,,,,,,,,,,,,,,,,12/Dec/19 15:51;xkrogen;Just committed this to trunk. Thanks for the contribution [~tasanuma]!,"12/Dec/19 16:05;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17757 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17757/])HDFS-15044. [Dynamometer] Show the line of audit log when parsing it (xkrogen: rev c210cede5ce143a0c12646d82d657863f0ec96b6)* (edit) hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-workload/src/main/java/org/apache/hadoop/tools/dynamometer/workloadgenerator/audit/AuditLogDirectParser.java","13/Dec/19 00:28;tasanuma;Thanks for reviewing and committing it, [~xkrogen]!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Correct target DN's log while balancing.,HDFS-15027,13271677,,Bug,Patch Available,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Minor,,xudongcao,xudongcao,xudongcao,02/12/2019 11:48,13/01/2020 01:53,18/01/2020 01:03,,3.2.1,,,,,,,,,,,,balancer & mover,,,,,02/12/2019 00:00,0,,,"During HDFS balancing, after the target DN copied a block from the proxy DN, it prints a log following the pattern below:*Moved BLOCK from BALANCER*This is wrong and misleading, maybe we can improve the pattern like:*Moved BLOCK complete, copied from PROXY DN, initiated by*Â *BALANCER*Â An example log of target DN during balancing:1. Wrong log printing before jira:{code:java}2019-12-04 09:33:19,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Moved BP-1426342230-192.168.202.11-1575277482603:blk_1073741889_1065 from /192.168.202.13:56322, delHint=54a14a41-0d7c-4487-b4f0-ce2848f86b48{code}2. Correct log printing after jira:{code:java}2019-12-12 10:06:34,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Moved BP-1360308441-192.168.202.11-1576116241828:blk_1073741872_1048 complete, copied from /192.168.202.11:9866, initiated by /192.168.202.13:53536, delHint=c70406f8-a815-4f6f-bdf0-fd3661bd6920{code}",,weichiu,xudongcao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,04/Dec/19 02:38;xudongcao;HDFS-15027.000.patch;https://issues.apache.org/jira/secure/attachment/12987421/HDFS-15027.000.patch,12/Dec/19 02:13;xudongcao;HDFS-15027.001.patch;https://issues.apache.org/jira/secure/attachment/12988628/HDFS-15027.001.patch,,,,,,,,,,,,,,,,,,,,,,,2,,,,,,,,,,,,,,,,,,,02:03.3,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Mon Jan 13 01:53:41 UTC 2020,,,,,,0|z096t4:,9.22337E+18,,,,,,,,,,,,,,,,,,"02/Dec/19 15:02;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 15s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 23m 17s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 19s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 28s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 52s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 35s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 22s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 13s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 18s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 38s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 50s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 20s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}106m 31s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 32s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}179m 54s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits ||   | hadoop.hdfs.TestDFSInotifyEventInputStreamKerberized ||   | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport ||   | hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:104ccca9169 || JIRA Issue | HDFS-15027 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12987291/HDFS-15027.000.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux a9e9991bdc88 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 6b2d6d4 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28430/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28430/testReport/ || Max. process+thread count | 2994 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28430/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.","02/Dec/19 16:01;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 33s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  1s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m 53s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  8s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 16s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 44s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 32s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  7s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  7s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 14s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 12s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 45s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 28s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}106m 59s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}177m 25s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDFSStorageStateRecovery ||   | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy ||   | hadoop.hdfs.TestErasureCodingPolicies ||   | hadoop.hdfs.TestDecommissionWithStriped ||   | hadoop.hdfs.TestDistributedFileSystemWithECFileWithRandomECPolicy ||   | hadoop.hdfs.TestDFSStripedOutputStream ||   | hadoop.hdfs.TestDistributedFileSystem ||   | hadoop.hdfs.TestReadStripedFileWithDNFailure ||   | hadoop.hdfs.server.balancer.TestBalancer ||   | hadoop.hdfs.security.TestDelegationTokenForProxyUser ||   | hadoop.hdfs.server.datanode.TestDataNodeUUID ||   | hadoop.hdfs.server.datanode.TestDataNodeMetrics ||   | hadoop.hdfs.TestFileAppend4 ||   | hadoop.hdfs.TestReadStripedFileWithDecoding ||   | hadoop.hdfs.TestFileChecksum ||   | hadoop.hdfs.TestDFSStripedOutputStreamWithRandomECPolicy |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:104ccca9169 || JIRA Issue | HDFS-15027 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12987293/HDFS-15027.000.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 7fdda56a13b2 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 6b2d6d4 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28431/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28431/testReport/ || Max. process+thread count | 3538 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28431/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",03/Dec/19 21:41;weichiu;Was the patch file deleted from the attachments?,"04/Dec/19 02:40;xudongcao;ccÂ [~weichiu]Â Sorry, patch uploaded again, this is just a minor log improvement, I think there's no need for unit test.","04/Dec/19 05:50;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 59s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 23m 22s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 17s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 18s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 17m 50s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 13s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 10s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 23s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 19s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red} 97m 45s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}167m 12s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean ||   | hadoop.hdfs.TestEncryptionZonesWithKMS |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:104ccca9169 || JIRA Issue | HDFS-15027 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12987421/HDFS-15027.000.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 074700de44c3 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 54e7605 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28442/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28442/testReport/ || Max. process+thread count | 2928 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28442/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.","12/Dec/19 02:09;xudongcao;[~weichiu] Perhaps we should keep the keyword ""Moved"" to reflect the meaning of moving block during balance, just like :*Moved BLOCK complete, copied from PROXY DN, initiated by*Â *BALANCER*","12/Dec/19 05:06;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 43s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 45s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 10s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 16s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 52s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 31s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 1 extant Findbugs warnings. {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 42s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 24s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}102m  5s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}165m 22s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.server.namenode.TestFsck |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:e573ea49085 || JIRA Issue | HDFS-15027 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12988628/HDFS-15027.001.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 22fa40b3b210 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 93bb368 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/28512/artifact/out/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28512/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28512/testReport/ || Max. process+thread count | 3077 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28512/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",13/Jan/20 01:53;xudongcao;[~weichiu]Â can this patch be merged now?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NN fails to parse Edit logs after applying HDFS-13101,HDFS-15012,13270559,,Bug,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Blocker,Fixed,shashikant,ericlin,ericlin,25/11/2019 23:23,18/12/2019 18:12,18/01/2020 01:03,18/12/2019 18:11,,,,,,2.10.0,2.8.0,2.9.0,3.1.0,3.2.0,3.3.0,,nn,,,,,,0,release-blocker,,"After applying HDFS-13101, and deleting and creating large number of snapshots, SNN exited with below error:  {code:sh}2019-11-18 08:28:06,528 ERROR org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader: Encountered exception on operation DeleteSnapshotOp [snapshotRoot=/path/to/hdfs/file, snapshotName=distcp-3479-31-old, RpcClientId=b16a6cb5-bdbb-45ae-9f9a-f7dc57931f37, RpcCallId=1]java.lang.AssertionError: Element already exists: element=partition_isactive=true, DELETED=[partition_isactive=true]        at org.apache.hadoop.hdfs.util.Diff.insert(Diff.java:193)        at org.apache.hadoop.hdfs.util.Diff.delete(Diff.java:239)        at org.apache.hadoop.hdfs.util.Diff.combinePosterior(Diff.java:462)        at org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature$DirectoryDiff$2.initChildren(DirectoryWithSnapshotFeature.java:240)        at org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature$DirectoryDiff$2.iterator(DirectoryWithSnapshotFeature.java:250)        at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.cleanSubtreeRecursively(INodeDirectory.java:755)        at org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature.cleanDirectory(DirectoryWithSnapshotFeature.java:753)        at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.cleanSubtree(INodeDirectory.java:790)        at org.apache.hadoop.hdfs.server.namenode.INodeReference.cleanSubtree(INodeReference.java:332)        at org.apache.hadoop.hdfs.server.namenode.INodeReference$WithName.cleanSubtree(INodeReference.java:583)        at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.cleanSubtreeRecursively(INodeDirectory.java:760)        at org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature.cleanDirectory(DirectoryWithSnapshotFeature.java:753)        at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.cleanSubtree(INodeDirectory.java:790)        at org.apache.hadoop.hdfs.server.namenode.snapshot.DirectorySnapshottableFeature.removeSnapshot(DirectorySnapshottableFeature.java:235)        at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.removeSnapshot(INodeDirectory.java:259)        at org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager.deleteSnapshot(SnapshotManager.java:301)        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.applyEditLogOp(FSEditLogLoader.java:688)        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:232)        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:141)        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:903)        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:756)        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:324)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1144)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:796)        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:614)        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:676)        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:844)        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:823)        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1547)        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1615){code}We confirmed that fsimage and edit files were NOT corrupted, as reverting HDFS-13101 fixed the issue. So the logic introduced in HDFS-13101 is broken and failed to parse edit log files.",,arp,ayushtkn,bharat,ericlin,hudson,risyomei,shashikant,smeng,sodonnell,surendrasingh,szetszwo,weichiu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,06/Dec/19 19:38;shashikant;HDFS-15012.000.patch;https://issues.apache.org/jira/secure/attachment/12987780/HDFS-15012.000.patch,12/Dec/19 05:51;shashikant;HDFS-15012.001.patch;https://issues.apache.org/jira/secure/attachment/12988642/HDFS-15012.001.patch,,,,,,,,,,,,,,,,,,,,,,,2,,,,,,,,,,,,,,,,,,,02:47.3,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Wed Dec 18 18:11:49 UTC 2019,,,,,,0|z08zwo:,9.22337E+18,,,,,,,,,2.10.1,2.8.6,2.9.3,3.0.4,3.1.4,3.2.2,3.3.0,,,"26/Nov/19 03:02;ayushtkn;Thanx [~ericlin] for the report.Do you propose a fix for this?[~shashikanth] [~weichiu] Pls give a check once!!!","26/Nov/19 03:25;weichiu;[~ericlin] is my colleague.We recently received several reports regarding corrupt fsimage or edit logs that fail to apply due to snapshot related operations. They happened on the version of HDFS with HDFS-13101, which is supposed to kill snapshot bugs once and for all. However it didn't.We are actively investigating it but so far not a solution yet.[~shashikant] [~sodonnell] FYI.","26/Nov/19 10:09;ericlin;Thanks [~weichiu],Hopefully we can nail it down soon.","26/Nov/19 18:26;surendrasingh;[~ericlin], can you attach test patch to reproduce this issue ?","01/Dec/19 00:21;ericlin;[~surendrasingh],i am a support engineer, not a developer. We do have fsimage and edit files to re-produce the issue. [~weichiu] & [~shashikant] can you please help to develop a patch to re-produce the issue?Thanks","03/Dec/19 18:41;weichiu;We are actively working on this. However given the nature of the problem it is not easy to reproduce in a unit test format.To be on the safe side, I would suggest reverting HDFS-13101 for now.Bump the priority to blocker and add release-blocker label to this jira.","03/Dec/19 18:56;ayushtkn;HDFS-13101 is fixing FSImage Corruption, that too seems a critical bug fix, Will reverting that not make it vulnerable?Moreover that has been released too as part of lower versions.Reverting would solve this problem but would open up the older problem. IMO Reverting isn't going to give any big relief, Anyway there is no release planned soon, you all can take some more time to get the solution.If you have any more pointers to how to reproduce the problem, let us know we can try help too..",06/Dec/19 19:39;shashikant;Patch v0 adds a unit test and fix to address the issue.,"06/Dec/19 22:49;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m 25s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  0s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  7s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m  4s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 57s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 26s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 16s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 13s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 13s{color} | {color:green} the patch passed {color} || {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 53s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 2 new + 141 unchanged - 0 fixed = 143 total (was 141) {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 29s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m  4s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 57s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 27s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}117m 33s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 47s{color} | {color:red} The patch generated 1 ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}187m 58s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes ||   | hadoop.hdfs.web.TestWebHDFSAcl ||   | hadoop.hdfs.web.TestWebHDFSForHA ||   | hadoop.hdfs.server.namenode.TestAuditLogs ||   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA ||   | hadoop.hdfs.server.namenode.TestFileTruncate ||   | hadoop.hdfs.web.TestWebHDFS ||   | hadoop.hdfs.server.namenode.TestFSEditLogLoader ||   | hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics ||   | hadoop.hdfs.server.namenode.TestLeaseManager ||   | hadoop.hdfs.TestFileChecksum ||   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery ||   | hadoop.hdfs.server.namenode.TestPersistentStoragePolicySatisfier ||   | hadoop.hdfs.web.TestWebHDFSXAttr ||   | hadoop.hdfs.TestEncryptedTransfer ||   | hadoop.hdfs.web.TestWebHdfsTokens |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.4 Server=19.03.4 Image:yetus/hadoop:104ccca9169 || JIRA Issue | HDFS-15012 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12987780/HDFS-15012.000.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 24a91f33000d 4.15.0-70-generic #79-Ubuntu SMP Tue Nov 12 10:36:11 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 76bb297 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28476/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28476/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28476/testReport/ || asflicense | https://builds.apache.org/job/PreCommit-HDFS-Build/28476/artifact/out/patch-asflicense-problems.txt || Max. process+thread count | 3315 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28476/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",09/Dec/19 15:19;szetszwo;+1 the 000 patch looks good.,12/Dec/19 05:52;shashikant;Thanks [~szetszwo]Â . Patch v1 addresses the checkstyle issues.,"12/Dec/19 08:44;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 44s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 21s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  6s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 29s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 13s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 1 extant Findbugs warnings. {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 11s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 33s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 17s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  9s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:green}+1{color} | {color:green} unit {color} | {color:green}102m 24s{color} | {color:green} hadoop-hdfs in the patch passed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 32s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}164m  6s{color} | {color:black} {color} |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:e573ea49085 || JIRA Issue | HDFS-15012 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12988642/HDFS-15012.001.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 5b7f69772808 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 93bb368 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/28513/artifact/out/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28513/testReport/ || Max. process+thread count | 2814 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28513/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",17/Dec/19 17:27;arp;+1 for the updated patch.,"18/Dec/19 17:36;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17773 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17773/])HDFS-15012. NN fails to parse Edit logs after applying HDFS-13101. (shashikant: rev fdd96e46d1f89f0ecdb9b1836dc7fca9fbb954fd)* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/DirectoryWithSnapshotFeature.java* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java","18/Dec/19 18:11;shashikant;Thanks [~ericlin]Â for helping discovering the issue. Thanks [~arp], [~szetszwo], [~weichiu], [~ayushtkn] [~surendrasingh]Â for the review and feedback. I have committed this. The findbug issue reported is not related.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use log variable directly instead of passing as argument in InvalidateBlocks#printBlockDeletionTime(),HDFS-14995,13269287,,Improvement,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Minor,Fixed,leosun08,leosun08,leosun08,19/11/2019 10:12,20/11/2019 18:54,18/01/2020 01:03,20/11/2019 18:42,,,,,,3.3.0,,,,,,,,,,,,,0,,,Refactor {{InvalidateBlocks#printBlockDeletionTime()}}.,,ayushtkn,elgoiri,hudson,leosun08,surendrasingh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,19/Nov/19 10:13;leosun08;HDFS-14995.001.patch;https://issues.apache.org/jira/secure/attachment/12986221/HDFS-14995.001.patch,19/Nov/19 15:17;leosun08;HDFS-14995.002.patch;https://issues.apache.org/jira/secure/attachment/12986248/HDFS-14995.002.patch,,,,,,,,,,,,,,,,,,,,,,,2,,,,,,,,,,,,,,,,,,,04:52.2,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Wed Nov 20 18:54:19 UTC 2019,,,,,,0|z08s20:,9.22337E+18,,,,,,,,,,,,,,,,,,"19/Nov/19 13:04;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 25s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 26m 47s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  8s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 22s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 27s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 31s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 16s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  6s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} || {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 40s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 1 new + 3 unchanged - 0 fixed = 4 total (was 3) {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  9s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 23s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 41s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red} 90m 54s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 32s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}163m 59s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestReconstructStripedFile ||   | hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer ||   | hadoop.hdfs.server.namenode.TestRedudantBlocks |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:104ccca9169 || JIRA Issue | HDFS-14995 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12986221/HDFS-14995.001.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux f6e4d9d1e68c 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 3cecb2a || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28337/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28337/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28337/testReport/ || Max. process+thread count | 3458 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28337/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.","19/Nov/19 14:37;ayushtkn;Thanx [~leosun08] can you handle the checkstyle warning?Apart LGTM","19/Nov/19 18:12;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 44s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 20m 12s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  2s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  9s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 44s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 14s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 11s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  7s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  6s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  6s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 41s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 59s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 24s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 14s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}106m 59s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}171m 10s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer ||   | hadoop.hdfs.TestDecommissionWithStriped ||   | hadoop.hdfs.TestMultipleNNPortQOP |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:104ccca9169 || JIRA Issue | HDFS-14995 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12986248/HDFS-14995.002.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 11e77e56c6bd 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 9fbfe6c || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28339/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28339/testReport/ || Max. process+thread count | 2753 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28339/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.","19/Nov/19 18:14;elgoiri;This is not exactly a refactor, can you explain the motivation?","20/Nov/19 02:11;leosun08;hi [~elgoiri]this Jira' s purpose is to unify code sytle.Define BlockManager.LOG inÂ InvalidateBlocks#invalidateWork as follow. Thank you.{code:java}synchronized List<Block> invalidateWork(final DatanodeDescriptor dn) {  final long delay = getInvalidationDelay();  if (delay > 0) {    BlockManager.LOG        .debug(""Block deletion is delayed during NameNode startup. ""            + ""The deletion will start after {} ms."", delay);    return null;  } ...}{code}",20/Nov/19 17:46;elgoiri;+1 on  [^HDFS-14995.002.patch].,20/Nov/19 18:26;surendrasingh;+1,"20/Nov/19 18:43;surendrasingh;Thanks [~leosun08] for contribution.Committed to trunk.","20/Nov/19 18:54;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17675 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17675/])HDFS-14995. Use log variable directly instead of passing as argument in (surendralilhore: rev fd264b826576b67adb04586002c3f94b7ea5a2f1)* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/InvalidateBlocks.java",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BlockStateChange logging is exceedingly verbose,HDFS-14981,13267779,,Bug,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Major,Duplicate,,ndimiduk,ndimiduk,12/11/2019 17:06,12/11/2019 18:14,18/01/2020 01:03,12/11/2019 18:14,,,,,,,,,,,,,logging,,,,,,0,,,"On a moderately loaded cluster, name node logs are flooded with entries of {{INFO BlockStateChange...}}, to the tune of ~30 lines per millisecond. This provides operators with little to no usable information. I suggest reducing this log message to {{DEBUG}}. Perhaps this information (and other logging related to it) should be directed to a dedicated block-audit.log file that can be queried, rotated on a separate schedule from the log of the main process.",,ndimiduk,weichiu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-6860,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,19:39.6,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Tue Nov 12 18:14:27 UTC 2019,,,,,,0|z08irc:,9.22337E+18,,,,,,,,,,,,,,,,,,12/Nov/19 17:19;weichiu;I think this is done by HDFS-6860.,"12/Nov/19 18:14;ndimiduk;Yep, I think you're right. Thanks for the pointer [~weichiu].",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RBF: ConnectionPool#newConnection() error log wrong protocol class,HDFS-14962,13266708,,Bug,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Minor,Fixed,John Smith,John Smith,John Smith,07/11/2019 02:31,11/11/2019 05:42,18/01/2020 01:03,11/11/2019 05:21,3.3.0,,,,,3.3.0,,,,,,,rbf,,,,,,0,RBF,,"ConnectionPool#newConnection() has following code:{code:java}String msg = ""Unsupported protocol for connection to NameNode: ""    + ((proto != null) ? proto.getClass().getName() : ""null"");{code}*proto.getClass().getName()*Â should beÂ *proto.getName()*My IDE can figure out the issue.",,ayushtkn,elgoiri,hudson,John Smith,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,21:25.7,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,Reviewed,,,,Mon Nov 11 05:42:16 UTC 2019,,,,,,0|z08c5c:,9.22337E+18,,,,,,,,RBF,3.3.0,,,,,,,,,07/Nov/19 02:40;John Smith;Very *small* PR created.,"11/Nov/19 05:21;ayushtkn;Merged.Thanx [~John Smith] for the contribution and [~elgoiri] for the review!!!","11/Nov/19 05:42;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17624 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17624/])HDFS-14962. RBF: ConnectionPool#newConnection() error log wrong protocol (ayushsaxena: rev b25a37c3229e1a66699d649f6caf80ffc71db5b8)* (edit) hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/ConnectionPool.java* (edit) hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestConnectionManager.java",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RBF: Router Safemode status should display properly without any unnecessary time-stamp and info log,HDFS-14956,13266579,,Improvement,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Minor,Not A Problem,,SouryakantaDwivedy,SouryakantaDwivedy,06/11/2019 12:50,15/11/2019 06:17,18/01/2020 01:03,15/11/2019 06:17,3.1.1,,,,,,,,,,,,rbf,,,,,,0,,,"Router Safemode status should display properly without any unnecesary time-stamp and info logStep:- * Make the Router Safemode On/Off * Â Get the Safemode info and check the output formatActual output :-Â Actual output :-Â Â  Â  Â Â ./hdfs dfsrouteradmin -safemode get2019-11-06 17:00:20,209 INFO federation.RouterAdmin: Router org.apache.hadoop.hdfs.protocolPB.RouterAdminProtocolTranslatorPB@31304f14 safemode status : trueSafe Mode: trueExpected Output :-Â  Â  Â  Â  Â  Router safemode status : trueÂ  Â  Â  Â Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Safe Mode: true",RBF Cluster,elgoiri,SouryakantaDwivedy,surendrasingh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,06/Nov/19 12:50;SouryakantaDwivedy;RBF_Safemode_log.PNG;https://issues.apache.org/jira/secure/attachment/12985057/RBF_Safemode_log.PNG,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,13:45.0,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Fri Nov 15 06:16:46 UTC 2019,,,,,,0|z08bco:,9.22337E+18,,,,,,,,,,,,,,,,,,"06/Nov/19 13:13;hemanthboyina;hi [~SouryakantaDwivedy]Â  thanks for raising the issueare you getting this issue on trunk ?Â can you please check and confirm","15/Nov/19 06:16;surendrasingh;[~SouryakantaDwivedy], you are getting this because in your log4j configuration {{hadoop.root.logger}}Â configured with {{console}}. If you change it to {{RFA}} then you will not get this log on console.one more option is you can set {{HADOOP_ROOT_LOGGER}} with ""INFO, RFA"" to avoid this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Revise PacketResponder's log.,HDFS-14945,13265460,,Bug,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Minor,Fixed,xudongcao,xudongcao,xudongcao,31/10/2019 07:14,04/11/2019 17:56,18/01/2020 01:03,04/11/2019 17:41,3.1.3,,,,,3.1.4,3.2.2,3.3.0,,,,,datanode,,,,,,0,,,"For a datanode in a pipeline, when its PacketResponder thread encounters an exception, it prints logs like below:2019-10-24 09:22:58,212 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in *BlockReceiver*.run():Â But this log is incorrect and misleading, the right print shoud be:2019-10-24 09:22:58,212 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in *PacketResponder*.run():",,hudson,weichiu,xudongcao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,31/Oct/19 07:18;xudongcao;HDFS-14945.000.patch;https://issues.apache.org/jira/secure/attachment/12984447/HDFS-14945.000.patch,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,25:49.6,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Mon Nov 04 17:56:20 UTC 2019,,,,,,0|z084g0:,9.22337E+18,,,,,,,,,,,,,,,,,,"31/Oct/19 10:25;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 13s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 24m 25s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 13s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 52s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 24s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 52s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 36s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 34s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 21s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 21s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 30s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 50s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 28s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}109m 58s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 36s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}185m  4s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDistributedFileSystem ||   | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean ||   | hadoop.hdfs.tools.TestDFSZKFailoverController |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.4 Server=19.03.4 Image:yetus/hadoop:104ccca9169 || JIRA Issue | HDFS-14945 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12984447/HDFS-14945.000.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 1ec1cc06bd42 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / e6137d0 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28212/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28212/testReport/ || Max. process+thread count | 2540 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28212/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",01/Nov/19 23:13;weichiu;+1,04/Nov/19 17:41;weichiu;Thanks!,"04/Nov/19 17:56;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17601 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17601/])HDFS-14945. Revise PacketResponder's log. Contributed by Xudong Cao. (weichiu: rev eb73ba6ed5f7c5500cc0ef36ca22aae4e71046fa)* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,