Summary,Issue key,Issue id,Parent id,Issue Type,Status,Project key,Project name,Project type,Project lead,Project description,Project url,Priority,Resolution,Assignee,Reporter,Creator,Created,Updated,Last Viewed,Resolved,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Component/s,Component/s,Component/s,Component/s,Component/s,Due Date,Votes,Labels,Labels,Description,Environment,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Original Estimate,Remaining Estimate,Time Spent,Work Ratio,� Original Estimate,� Remaining Estimate,� Time Spent,Security Level,Outward issue link (Blocker),Outward issue link (Blocker),Outward issue link (Blocker),Outward issue link (Blocker),Outward issue link (Blocker),Outward issue link (Container),Outward issue link (Duplicate),Outward issue link (Incorporates),Outward issue link (Incorporates),Outward issue link (Incorporates),Outward issue link (Incorporates),Outward issue link (Problem/Incident),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Regression),Outward issue link (Regression),Outward issue link (Required),Outward issue link (Supercedes),Outward issue link (Supercedes),Outward issue link (Supercedes),Outward issue link (Supercedes),Outward issue link (dependent),Outward issue link (dependent),Outward issue link (dependent),Outward issue link (dependent),Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Custom field (Attachment count),Custom field (Blog - New Blog Administrators),Custom field (Blog - New Blog PMC),Custom field (Blog - Write access),Custom field (Blog Administrator?),Custom field (Blogs - Admin for blog),Custom field (Blogs - Email Address),Custom field (Blogs - Existing Blog Access Level),Custom field (Blogs - Existing Blog Name),Custom field (Blogs - New Blog Write Access),Custom field (Blogs - Username),Custom field (Bug Category),Custom field (Bugzilla - Email Notification Address),Custom field (Bugzilla - List of usernames),Custom field (Bugzilla - PMC Name),Custom field (Bugzilla - Project Name),Custom field (Bugzilla Id),Custom field (Change Category),Custom field (Complexity),Custom field (Date of First Response),Custom field (Discovered By),Custom field (Docs Text),Custom field (Enable Automatic Patch Review),Custom field (Epic Colour),Custom field (Epic Link),Custom field (Epic Name),Custom field (Epic Status),Custom field (Existing GitBox Approval),Custom field (External issue ID),Custom field (External issue URL),Custom field (Flags),Custom field (Flags),Custom field (Git Notification Mailing List),Custom field (Git Repository Import Path),Custom field (Git Repository Name),Custom field (Git Repository Type),Custom field (GitHub Options),Custom field (Github Integration),Custom field (Github Integrations - Other),Custom field (Global Rank),Custom field (Hadoop Flags),Custom field (Hadoop Flags),Custom field (INFRA - Subversion Repository Path),Custom field (Initial Confluence Contributors),Custom field (Last public comment date),Custom field (Machine Readable Info),Custom field (New-TLP-TLPName),Custom field (Priority),Custom field (Project),Custom field (Protected Branch),Custom field (Rank),Custom field (Rank (Obsolete)),Custom field (Release Note),Custom field (Severity),Custom field (Severity),Custom field (Source Control Link),Custom field (Space Description),Custom field (Space Key),Custom field (Space Name),Custom field (Tags),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Test and Documentation Plan),Custom field (Testcase included),Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,CommentCrashing bugs in NameNode when using a valid configuration for `dfs.namenode.audit.loggers`,HDFS-15124,13279452,,Bug,Patch Available,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Critical,,,ctest.team,ctest.team,14/01/2020 22:34,17/01/2020 02:12,18/01/2020 01:02,,2.10.0,,,,,,,,,,,,namenode,,,,,,0,,,"I am using Hadoop-2.10.0.The configuration parameter `dfs.namenode.audit.loggers` allows `default` (which is the default value) and `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`.When I use `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`, namenode will not be started successfully because of an `InstantiationException` thrown from `org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers`.��The root cause is that while initializing namenode, `initAuditLoggers` will be called and it will try to call the default constructor of `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger` which doesn't have a default constructor. Thus the `InstantiationException` exception is thrown.��*Symptom**$ ./start-dfs.sh*{code:java}2019-12-18 14:05:20,670 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.java.lang.RuntimeException: java.lang.InstantiationException: org.apache.hadoop.hdfs.server.namenode.top.TopAuditLoggerat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1024)at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:858)at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:677)at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:674)at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:736)at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:961)at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:940)at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1714)at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1782)Caused by: java.lang.InstantiationException: org.apache.hadoop.hdfs.server.namenode.top.TopAuditLoggerat java.lang.Class.newInstance(Class.java:427)at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1017)...8 moreCaused by: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger.<init>()at java.lang.Class.getConstructor0(Class.java:3082)at java.lang.Class.newInstance(Class.java:412)... 9 more{code}����*Detailed Root Cause*There is no default constructor in `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`:��{code:java}/**  * An {@link AuditLogger} that sends logged com.issue.iaserver.data directly to the metrics * systems. It is used when the top service is used directly by the name node  */ @InterfaceAudience.Private public class TopAuditLogger implements AuditLogger {       public static finalLogger LOG = LoggerFactory.getLogger(TopAuditLogger.class);   private final TopMetrics topMetrics;   public TopAuditLogger(TopMetrics topMetrics) {    Preconditions.checkNotNull(topMetrics, ""Cannot init with a null "" +         ""TopMetrics"");    this.topMetrics = topMetrics;   }  @Override  public void initialize(Configuration conf) {   }{code}As long as the configuration parameter `dfs.namenode.audit.loggers` is set to `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`, `initAuditLoggers` will try to call its default constructor to make a new instance:��{code:java}private List<AuditLogger> initAuditLoggers(Configuration conf) {�� // Initialize the custom access loggers if configured.�� Collection<String> alClasses =�� �� �� conf.getTrimmedStringCollection(DFS_NAMENODE_AUDIT_LOGGERS_KEY);�� List<AuditLogger> auditLoggers = Lists.newArrayList();�� if (alClasses != null && !alClasses.isEmpty()) {�� �� for (String className : alClasses) {�� �� �� try {�� �� �� �� AuditLogger logger;�� �� �� �� if (DFS_NAMENODE_DEFAULT_AUDIT_LOGGER_NAME.equals(className)) {�� �� �� �� �� logger = new DefaultAuditLogger();�� �� �� �� } else {�� �� �� �� �� logger = (AuditLogger) Class.forName(className).newInstance();�� �� �� �� }�� �� �� �� logger.initialize(conf);�� �� �� �� auditLoggers.add(logger);�� �� �� } catch (RuntimeException re) {�� �� �� �� throw re;�� �� �� } catch (Exception e) {�� �� �� �� throw new RuntimeException(e);�� �� �� }�� �� }�� }{code}`initAuditLoggers` tries to call the default constructor to make a new instance in:{code:java}logger = (AuditLogger) Class.forName(className).newInstance();{code}This is very different from the default configuration, `default`, which implements a default constructor so the default is fine.��*How To Reproduce*��The version of Hadoop: 2.10.0 # Set the value of configuration parameter `dfs.namenode.audit.loggers` to `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger` in ""hdfs-site.xml""(the default value is `default`) # Start the namenode by running ""start-dfs.sh"" # The namenode will not be started successfully.{code:java}<property>����<name>dfs.namenode.audit.loggers</name>����<value>org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger</value>����<description>��������List of classes implementing audit loggers that will receive audit events.��������These should be implementations of org.apache.hadoop.hdfs.server.namenode.AuditLogger.��������The special value ""default"" can be used to reference the default audit��������logger, which uses the configured log system. Installing custom audit loggers��������may affect the performance and stability of the NameNode. Refer to the custom��������logger's documentation for more details.����</description></property>{code}��*How To Fix*Add a default constructor for `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`.I wrote a patch to add a default constructor for��TopAuditLogger.",,ctest.team,elgoiri,weichiu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15/Jan/20 02:25;ctest.team;HDFS-15124.000.patch;https://issues.apache.org/jira/secure/attachment/12990931/HDFS-15124.000.patch,16/Jan/20 17:25;ctest.team;HDFS-15124.001.patch;https://issues.apache.org/jira/secure/attachment/12991162/HDFS-15124.001.patch,16/Jan/20 22:56;ctest.team;HDFS-15124.002.patch;https://issues.apache.org/jira/secure/attachment/12991181/HDFS-15124.002.patch,,,,,,,,,,,,,,,,,,,,,,3,,,,,,,,,,,,,,,,,,,42:12.5,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Fri Jan 17 02:12:05 UTC 2020,,,,,,0|z0aig0:,9.22337E+18,,,,,,,,,,,,,,,,,,"14/Jan/20 22:42;weichiu;You shouldn't need to add TopAuditLogger to auditlogger configuration. As long as dfs.namenode.top.enabled is true (default), it is added.","14/Jan/20 23:16;ctest.team;[~weichiu] Thank you for your reply!Yes. The default value can also add��TopAuditLogger, but most users don't read the src code and don't know it.If the users want to use��TopAuditLogger and they directly set it to��TopAuditLogger (without understanding the src code), then the namenode will crash.I wrote a patch to add the default constructor for the��TopAuditLogger which I think can make this part more robust.","14/Jan/20 23:39;elgoiri;In addition to the constructor, the exception for this case is a little verbose and not intuitive.Is there a way we can improve that too?One can follow the full stack trace but it is buried...","15/Jan/20 03:01;ctest.team;[~elgoiri]��Thank you for your reply and this is a good point! How about catching InstantiationException in `initAuditLoggers(Configuration conf)`It will look like:{code:java}private List<AuditLogger> initAuditLoggers(Configuration conf) {  // Initialize the custom access loggers if configured.  Collection<String> alClasses =      conf.getTrimmedStringCollection(DFS_NAMENODE_AUDIT_LOGGERS_KEY);  List<AuditLogger> auditLoggers = Lists.newArrayList();  if (alClasses != null && !alClasses.isEmpty()) {    for (String className : alClasses) {      try {        AuditLogger logger;        if (DFS_NAMENODE_DEFAULT_AUDIT_LOGGER_NAME.equals(className)) {          logger = new DefaultAuditLogger();        } else {          logger = (AuditLogger) Class.forName(className).newInstance();        }        logger.initialize(conf);        auditLoggers.add(logger);      } catch (InstantiationException e) {        LOG.error(""Instantiation error for "" + className);        throw new RuntimeException(e);      } catch (RuntimeException re) {        throw re;      } catch (Exception e) {        throw new RuntimeException(e);      }    }  }{code}The log error message can be refined. I can upload another patch for this if this is the right way to do it.","15/Jan/20 05:30;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 45s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 24m 26s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  7s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 34s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 12s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 20s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 35s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 25s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 10s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 13s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}115m 21s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}180m 15s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.server.namenode.TestRedudantBlocks |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:c44943d1fc3 || JIRA Issue | HDFS-15124 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12990931/HDFS-15124.000.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 778f53fdcbb8 4.15.0-65-generic #74-Ubuntu SMP Tue Sep 17 17:06:04 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / c36f09d || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_232 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28675/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28675/testReport/ || Max. process+thread count | 3894 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28675/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.","15/Jan/20 18:37;elgoiri;Thanks [~ctest.team] for the proposal, yes, I think it makes sense.Just use the logger style with {}.",15/Jan/20 19:45;weichiu;Please make sure you don't add TopAuditLogger twice by setting dfs.namenode.top.enabled to TopAuditLogger.,16/Jan/20 02:05;ctest.team;[~elgoiri] [~weichiu] Sure. I will upload a new patch to do that. Thank you for your suggestions.,"16/Jan/20 17:32;ctest.team;I uploaded a new patch to do all these changes.[~elgoiri]��I am sorry I didn't use {} style for the LOG in FSNamesystem.java because in��FSNamesystem.java the LOG is `org.apache.commons.logging.Log` instead of `org.slf4j.Logger`. The��`org.apache.commons.logging.Log` doesn't support{code:java}LOG.error(""xxx {}"", ""yyy""){code}Please let me know if anything else needed. Thank you!","16/Jan/20 17:48;elgoiri;FSNameSystem seems to be using logger, right?https://github.com/apache/hadoop/blob/a0ff42d7612e744e0bf88aa14078ea3ab6bcce49/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java#L373It was done by HDFS-12552.","16/Jan/20 19:08;ctest.team;[~elgoiri] Sorry that I was using hadoop-2.10.0 and the��FSNameSystem was using��{code:java}public static final Log LOG = LogFactory.getLog(FSNamesystem.class);{code}[https://github.com/apache/hadoop/blob/e2f1f118e465e787d8567dfa6e2f3b72a0eb9194/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java#L328]It seems that 3.x.x is using��org.slf4j.Logger but 2.x.x is using��org.apache.commons.logging.Log for FSNanesystem.java.I will write another patch for trunk and upload it again. Thank you for pointing this out!","16/Jan/20 20:49;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 51s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 55s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  4s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  8s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 29s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 19s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 15s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} || {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 41s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 1 new + 166 unchanged - 0 fixed = 167 total (was 166) {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  5s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 33s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 42s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 24s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}134m  8s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}198m 52s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDecommission ||   | hadoop.hdfs.server.namenode.snapshot.TestSnapshot ||   | hadoop.hdfs.server.namenode.TestINodeAttributeProvider ||   | hadoop.hdfs.TestDatanodeRegistration ||   | hadoop.hdfs.server.namenode.TestRedudantBlocks ||   | hadoop.hdfs.server.namenode.TestFSImage ||   | hadoop.hdfs.server.namenode.TestFsck ||   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:c44943d1fc3 || JIRA Issue | HDFS-15124 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12991162/HDFS-15124.001.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 8fac4d4b27be 4.15.0-74-generic #84-Ubuntu SMP Thu Dec 19 08:06:28 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / a0ff42d || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_232 || findbugs | v3.1.0-RC1 || checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28684/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28684/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28684/testReport/ || Max. process+thread count | 2649 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28684/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",17/Jan/20 01:19;ctest.team;Uploaded one new patch for trunk.,"17/Jan/20 02:12;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 41s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m 23s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  6s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 13s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 11s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 28s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 16s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} || {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 41s{color} | {color:orange} hadoop-hdfs-project/hadoop-hdfs: The patch generated 1 new + 166 unchanged - 0 fixed = 167 total (was 166) {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 13s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 25s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 45s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 24s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}123m 13s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 32s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}191m 22s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDeadNodeDetection ||   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks ||   | hadoop.hdfs.server.namenode.TestRedudantBlocks ||   | hadoop.hdfs.server.datanode.TestNNHandlesBlockReportPerStorage |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:c44943d1fc3 || JIRA Issue | HDFS-15124 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12991181/HDFS-15124.002.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 0fb99bc6d2d0 4.15.0-74-generic #84-Ubuntu SMP Thu Dec 19 08:06:28 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 263413e || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_232 || findbugs | v3.1.0-RC1 || checkstyle | https://builds.apache.org/job/PreCommit-HDFS-Build/28687/artifact/out/diff-checkstyle-hadoop-hdfs-project_hadoop-hdfs.txt || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28687/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28687/testReport/ || Max. process+thread count | 2570 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28687/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,RBF: Print stacktrace when DFSRouter fails to fetch/parse JMX output from NameNode,HDFS-15100,13278086,13241304,Sub-task,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Major,Fixed,aajisaka,aajisaka,aajisaka,08/01/2020 08:11,10/01/2020 04:31,18/01/2020 01:03,10/01/2020 04:18,,,,,,3.3.0,,,,,,,rbf,,,,,,0,supportability,,"When DFSRouter fails to fetch or parse JMX output from NameNode, it prints only the error message. Therefore we had to modify the source code to print the stacktrace of the exception to find the root cause.",,aajisaka,ayushsaxena,elgoiri,hudson,John Smith,tasanuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,01:15.6,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Fri Jan 10 04:31:43 UTC 2020,,,,,,0|z0aacg:,9.22337E+18,,,,,,,,,3.3.0,,,,,,,,,"08/Jan/20 14:01;elgoiri;Can you show the output of the trace before and after?I personally prefer single line messages for known exceptions. ","09/Jan/20 02:29;aajisaka;Thanks [~inigoiri] for your comment.This is the output: https://gist.github.com/aajisaka/33699d0ef825cf587e0bb4a5575c1939This change is for the errors that we have to find the root cause of and fix, so I'd like to see the detailed information.","09/Jan/20 17:47;elgoiri;A little verbose but I guess that's what we need, let me comment in the PR.","10/Jan/20 04:18;tasanuma;Committed to trunk. Thanks for your contribution, [~aajisaka]. Thanks for your review, [~elgoiri].","10/Jan/20 04:31;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17842 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17842/])HDFS-15100. RBF: Print stacktrace when DFSRouter fails to fetch/parse (tasanuma: rev 0315ef844862ee863d646b562ba6d8889876ffa9)* (edit) hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/FederationUtil.java",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,DataNode.DataTransfer thread should catch all the expception and log it.,HDFS-15074,13275454,,Improvement,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Major,Fixed,hemanthboyina,surendrasingh,surendrasingh,19/12/2019 09:47,29/12/2019 06:06,18/01/2020 01:03,29/12/2019 06:02,3.1.1,,,,,3.1.4,3.2.2,3.3.0,,,,,datanode,,,,,,0,,,"Some time If this thread is throwing exception other than IOException, will not be able to trash it.",,elgoiri,hemanthboyina,hudson,surendrasingh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,23/Dec/19 17:32;hemanthboyina;HDFS-15074.001.patch;https://issues.apache.org/jira/secure/attachment/12989389/HDFS-15074.001.patch,25/Dec/19 17:52;hemanthboyina;HDFS-15074.002.patch;https://issues.apache.org/jira/secure/attachment/12989464/HDFS-15074.002.patch,,,,,,,,,,,,,,,,,,,,,,,2,,,,,,,,,,,,,,,,,,,32:59.1,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Sun Dec 29 06:06:08 UTC 2019,,,,,,0|z09u48:,9.22337E+18,,,,,,,,,,,,,,,,,,"23/Dec/19 17:32;hemanthboyina;attached patch , please review","23/Dec/19 20:38;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 53s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 33s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  5s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 28s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 12s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 24s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 20s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 13s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}115m 42s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}177m 41s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDatanodeRegistration ||   | hadoop.hdfs.server.namenode.TestRedudantBlocks ||   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots ||   | hadoop.hdfs.TestFileChecksumCompositeCrc |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:c44943d1fc3 || JIRA Issue | HDFS-15074 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12989389/HDFS-15074.001.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux c2fd4ae01a33 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 34ff7db || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_232 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28559/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28559/testReport/ || Max. process+thread count | 2887 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28559/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.","25/Dec/19 15:56;surendrasingh;[~hemanthboyina], minor comment.Just log the exception like this{code:java}LOG.error(""Failed to transfer block "" + b, t); {code}","25/Dec/19 18:03;hemanthboyina;thanks for the review [~surendrasingh]��.����updated the patch , please review .��","25/Dec/19 20:56;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 57s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 30s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  4s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 39s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 16s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 12s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 29s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 19s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}103m 43s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}166m  2s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestFileChecksum ||   | hadoop.hdfs.TestDeadNodeDetection ||   | hadoop.hdfs.TestDatanodeRegistration ||   | hadoop.hdfs.server.namenode.TestRedudantBlocks ||   | hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots ||   | hadoop.hdfs.TestFileChecksumCompositeCrc ||   | hadoop.hdfs.TestRollingUpgrade |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:c44943d1fc3 || JIRA Issue | HDFS-15074 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12989464/HDFS-15074.002.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 8d59a8e92c65 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 300505c || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_232 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28569/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28569/testReport/ || Max. process+thread count | 2963 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28569/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",27/Dec/19 06:57;surendrasingh;+1,"29/Dec/19 06:02;surendrasingh;Committed to trunk, branch-3.2, branch-3.1","29/Dec/19 06:06;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17800 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17800/])HDFS-15074. DataNode.DataTransfer thread should catch all the expception (surendralilhore: rev ee51eadda01e02ac5759ca19756f6f961c8eb0cd)* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Duplicated: Crashing bugs in NameNode when using a valid configuration for `dfs.namenode.audit.loggers`,HDFS-15070,13275337,,Bug,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Critical,Duplicate,,XudongSun,XudongSun,18/12/2019 21:26,14/01/2020 23:04,18/01/2020 01:03,14/01/2020 23:03,2.10.0,,,,,,,,,,,,namenode,,,,,,0,,,"I am using Hadoop-2.10.0.The configuration parameter `dfs.namenode.audit.loggers` allows `default` (which is the default value) and `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`.When I use `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`, namenode will not be started successfully because of an `InstantiationException` thrown from `org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers`.��The root cause is that while initializing namenode, `initAuditLoggers` will be called and it will try to call the default constructor of `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger` which doesn't have a default constructor. Thus the `InstantiationException` exception is thrown.��*Symptom**$ ./start-dfs.sh*��{code:java}2019-12-18 14:05:20,670 ERROR org.apache.hadoop.hdfs.server.namenode.FSNamesystem: FSNamesystem initialization failed.java.lang.RuntimeException: java.lang.InstantiationException: org.apache.hadoop.hdfs.server.namenode.top.TopAuditLoggerat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1024)at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:858)at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:677)at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:674)at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:736)at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:961)at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:940)at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1714)at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1782)Caused by: java.lang.InstantiationException: org.apache.hadoop.hdfs.server.namenode.top.TopAuditLoggerat java.lang.Class.newInstance(Class.java:427)at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1017)... 8 moreCaused by: java.lang.NoSuchMethodException: org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger.<init>()at java.lang.Class.getConstructor0(Class.java:3082)at java.lang.Class.newInstance(Class.java:412)... 9 more{code}����*Detailed Root Cause*There is no default constructor in `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`:{code:java}/**  * An {@link AuditLogger} that sends logged com.issue.iaserver.data directly to the metrics * systems. It is used when the top service is used directly by the name node  */ @InterfaceAudience.Private public class TopAuditLogger implements AuditLogger {       public static finalLogger LOG = LoggerFactory.getLogger(TopAuditLogger.class);   private final TopMetrics topMetrics;   public TopAuditLogger(TopMetrics topMetrics) {    Preconditions.checkNotNull(topMetrics, ""Cannot init with a null "" +         ""TopMetrics"");    this.topMetrics = topMetrics;   }  @Override  public void initialize(Configuration conf) {   }{code}As long as the configuration parameter `dfs.namenode.audit.loggers` is set to `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`, `initAuditLoggers` will try to call its default constructor to make a new instance:{code:java}private List<AuditLogger> initAuditLoggers(Configuration conf) {  // Initialize the custom access loggers if configured.  Collection<String> alClasses =      conf.getTrimmedStringCollection(DFS_NAMENODE_AUDIT_LOGGERS_KEY);  List<AuditLogger> auditLoggers = Lists.newArrayList();  if (alClasses != null && !alClasses.isEmpty()) {    for (String className : alClasses) {      try {        AuditLogger logger;        if (DFS_NAMENODE_DEFAULT_AUDIT_LOGGER_NAME.equals(className)) {          logger = new DefaultAuditLogger();        } else {          logger = (AuditLogger) Class.forName(className).newInstance();        }        logger.initialize(conf);        auditLoggers.add(logger);      } catch (RuntimeException re) {        throw re;      } catch (Exception e) {        throw new RuntimeException(e);      }    }  }{code}`initAuditLoggers` tries to call the default constructor to make a new instance in:{code:java}logger = (AuditLogger) Class.forName(className).newInstance();{code}This is very different from the default configuration, `default`, which implements a default constructor so the default is fine.��*How To Reproduce*��The version of Hadoop: 2.10.0 # Set the value of configuration parameter `dfs.namenode.audit.loggers` to `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger` in ""hdfs-site.xml""(the default value is `default`) # Start the namenode by running ""start-dfs.sh"" # The namenode will not be started successfully. ��{code:java}<property>����<name>dfs.namenode.audit.loggers</name>����<value>org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger</value>����<description>��������List of classes implementing audit loggers that will receive audit events.��������These should be implementations of org.apache.hadoop.hdfs.server.namenode.AuditLogger.��������The special value ""default"" can be used to reference the default audit��������logger, which uses the configured log system. Installing custom audit loggers��������may affect the performance and stability of the NameNode. Refer to the custom��������logger's documentation for more details.����</description></property>{code}��*How To Fix*Add a default constructor for `org.apache.hadoop.hdfs.server.namenode.top.TopAuditLogger`",,csun,elgoiri,tianyin,XudongSun,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,26:34.0,,,,,,0|z09te8:,9.22337E+18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Add LOG when sendIBRs failed,HDFS-15062,13274716,,Improvement,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Major,Fixed,ferhui,ferhui,ferhui,16/12/2019 09:30,20/12/2019 19:28,18/01/2020 01:03,20/12/2019 19:28,3.0.3,3.1.3,3.2.1,,,3.3.0,,,,,,,datanode,,,,,,0,,,"{code}  /** Send IBRs to namenode. */  void sendIBRs(DatanodeProtocol namenode, DatanodeRegistration registration,      String bpid, String nnRpcLatencySuffix) throws IOException {    // Generate a list of the pending reports for each storage under the lock    final StorageReceivedDeletedBlocks[] reports = generateIBRs();    if (reports.length == 0) {      // Nothing new to report.      return;    }    // Send incremental block reports to the Namenode outside the lock    if (LOG.isDebugEnabled()) {      LOG.debug(""call blockReceivedAndDeleted: "" + Arrays.toString(reports));    }    boolean success = false;    final long startTime = monotonicNow();    try {      namenode.blockReceivedAndDeleted(registration, bpid, reports);      success = true;    } finally {      if (success) {        dnMetrics.addIncrementalBlockReport(monotonicNow() - startTime,            nnRpcLatencySuffix);        lastIBR = startTime;      } else {        // If we didn't succeed in sending the report, put all of the        // blocks back onto our queue, but only in the case where we        // didn't put something newer in the meantime.        putMissing(reports);      }    }  }{code}When call namenode.blockReceivedAndDelete failed, will put reports to pendingIBRs. Maybe we should add log for failed case. It is helpful for trouble shooting",,ayushtkn,ebadger,elgoiri,ferhui,hexiaoqiao,hudson,weichiu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,16/Dec/19 09:35;ferhui;HDFS-15062.001.patch;https://issues.apache.org/jira/secure/attachment/12988913/HDFS-15062.001.patch,17/Dec/19 00:52;ferhui;HDFS-15062.002.patch;https://issues.apache.org/jira/secure/attachment/12988957/HDFS-15062.002.patch,19/Dec/19 01:16;ferhui;HDFS-15062.003.patch;https://issues.apache.org/jira/secure/attachment/12989151/HDFS-15062.003.patch,,,,,,,,,,,,,,,,,,,,,,3,,,,,,,,,,,,,,,,,,,39:40.8,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,Reviewed,,,,Fri Dec 20 19:27:38 UTC 2019,,,,,,0|z09pk8:,9.22337E+18,,,,,,,,,,,,,,,,,,16/Dec/19 12:15;ferhui;[~weichiu] [~ayushtkn] Could you please take a look ? Thanks,"16/Dec/19 13:39;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 43s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 21s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 38s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 13s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 11s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 27s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 17s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}103m 12s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 32s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}164m 52s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDeadNodeDetection ||   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:e573ea49085 || JIRA Issue | HDFS-15062 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12988913/HDFS-15062.001.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 7c1e2b89cbc7 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / dc6cf17 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28532/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28532/testReport/ || Max. process+thread count | 2778 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28532/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.","16/Dec/19 18:14;elgoiri;Not that it makes much of a difference with warn and this setting but it makes sense to use the logger format:{code}LOG.warn(""Failed to call blockReceivedAndDeleted: {}"", Arrays.toString(reports));{code}","17/Dec/19 00:52;ferhui;[~elgoiri] Thanks for your comments!Upload v002 patch",17/Dec/19 01:43;elgoiri;+1 on  [^HDFS-15062.002.patch].,"17/Dec/19 03:45;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 42s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 17s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 24s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 12s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 34s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 20s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  9s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}102m 44s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}164m 20s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDeadNodeDetection |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:e573ea49085 || JIRA Issue | HDFS-15062 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12988957/HDFS-15062.002.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 68f1356b8742 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 578bd10 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28535/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28535/testReport/ || Max. process+thread count | 2767 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28535/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",17/Dec/19 16:17;ayushtkn;v002 LGTM +1,18/Dec/19 04:23;weichiu;What's the typical reason for failing to send IBRs? Time outs? I'm wondering if logging the duration of the call can be useful too.,"18/Dec/19 05:21;ferhui;[~weichiu] Now didn't see failing. I found that sending IBRs was delayed because of handling invalid blocks.I think adding log is helpful for quick trouble shooting","18/Dec/19 06:12;hexiaoqiao;It seems very similar to HDFS-14997, maybe it could solve this issue. FYI.","18/Dec/19 15:44;ferhui;[~hexiaoqiao] Thanks for reminding me. HDFS-14997 is great work, it could resolve the problem that sending IBRs was delayed.This JIRA just adds key logs for quick trouble shooting.","18/Dec/19 18:08;elgoiri;[~weichiu] was also bringing up if we needed to add more information to the log message.He proposed the duration but maybe there are other things too.[~ferhui], just give it a thought to see if we should add more info.","19/Dec/19 01:18;ferhui;[~weichiu] [~elgoiri]I think adding more info is good.Upload v003 patch add nnId and duration info","19/Dec/19 03:51;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 32s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 16s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 41s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  6s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 30s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  6s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 16s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 35s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 17s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  8s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 18s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red} 91m 12s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}148m 35s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDeadNodeDetection ||   | hadoop.hdfs.TestMultipleNNPortQOP ||   | hadoop.hdfs.TestReconstructStripedFile |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:e573ea49085 || JIRA Issue | HDFS-15062 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12989151/HDFS-15062.003.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 88a4ee862d58 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 7b93575 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28542/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28542/testReport/ || Max. process+thread count | 3975 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28542/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",19/Dec/19 04:02;weichiu;LGTM,"19/Dec/19 17:41;elgoiri;The failed unit tests are unrelated, updating my vote and committing shortly.+1 on  [^HDFS-15062.003.patch]","19/Dec/19 17:49;elgoiri;Thanks [~ferhui] for the patch and [~weichiu] and [~ayushtkn] for the reviews.Pushed to trunk, branch-3.2, branch-3.1, and branch-3.0.","19/Dec/19 18:04;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17779 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17779/])HDFS-15062. Add LOG when sendIBRs failed. Contributed by Fei Hui. (inigoiri: rev 52d7b745c6d95e799542d6409dac30d0418ce8a8)* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/IncrementalBlockReportManager.java",20/Dec/19 19:03;ebadger;This patch breaks branch-3.2 and branch-3.1 compilation. Remember that you always need to compile the code on each branch before you merge. ,"20/Dec/19 19:23;ebadger;I have reverted this patch from branch-3.2 and branch-3.1. I didn't bother with branch-3.0, since that branch is no longer active. ","20/Dec/19 19:27;elgoiri;My bad, logger format...Reverted it from 3.0 just for cleanness.I'll close it as is with just 3.3 as target.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Optimize log information when DFSInputStream meet CannotObtainBlockLengthException,HDFS-15050,13273879,,Improvement,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Major,Fixed,hexiaoqiao,hexiaoqiao,hexiaoqiao,11/12/2019 13:17,12/12/2019 11:26,18/01/2020 01:03,12/12/2019 10:26,,,,,,2.10.1,2.9.3,3.1.4,3.2.2,3.3.0,,,dfsclient,,,,,,0,,,"We could not identify which file it belongs easily when DFSInputStream meet CannotObtainBlockLengthException, as the following exception log. Just suggest to log file path string when we meet CannotObtainBlockLengthException.{code:java}Caused by: java.io.IOException: Cannot obtain block length for LocatedBlock{BP-***:blk_***_***; getBlockSize()=690504; corrupt=false; offset=1811939328; locs=[DatanodeInfoWithStorage[*:50010,DS-2bcadcc4-458a-45c6-a91b-8461bf7cdd71,DISK], DatanodeInfoWithStorage[*:50010,DS-8f2bb259-ecb2-4839-8769-4a0523360d58,DISK], DatanodeInfoWithStorage[*:50010,DS-69f4de6f-2428-42ff-9486-98c2544b1ada,DISK]]}	at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:402)	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:345)	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:280)	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:272)	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1664)	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:304)	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:300)	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:300)	at org.apache.hadoop.fs.FilterFileSystem.open(FilterFileSystem.java:161)	at org.apache.hadoop.fs.viewfs.ChRootedFileSystem.open(ChRootedFileSystem.java:266)	at org.apache.hadoop.fs.viewfs.ViewFileSystem.open(ViewFileSystem.java:481)	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:828)	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)	at org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.<init>(CombineHiveRecordReader.java:65)	... 16 more{code}",,hexiaoqiao,hudson,weichiu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11/Dec/19 13:18;hexiaoqiao;HDFS-15050.001.patch;https://issues.apache.org/jira/secure/attachment/12988539/HDFS-15050.001.patch,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,16:07.8,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Thu Dec 12 10:38:47 UTC 2019,,,,,,0|z09ke8:,9.22337E+18,,,,,,,,,,,,,,,,,,11/Dec/19 13:20;hexiaoqiao;submit init patch with minor exception changes.,"11/Dec/19 14:16;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 26s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 16s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 26s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 54s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 55s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 34s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 41s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 30s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  1s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 29s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 55s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 29s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black} 55m 19s{color} | {color:black} {color} |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:104ccca9169 || JIRA Issue | HDFS-15050 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12988539/HDFS-15050.001.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 8fede6446889 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / c2e9783 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28503/testReport/ || Max. process+thread count | 420 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs-client U: hadoop-hdfs-project/hadoop-hdfs-client || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28503/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",11/Dec/19 16:43;weichiu;+1,12/Dec/19 10:26;weichiu;Thanks [~hexiaoqiao] for contributing the patch. I've committed the patch to trunk branch-3.2 and branch-3.1.,"12/Dec/19 10:38;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17755 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17755/])HDFS-15050. Optimize log information when DFSInputStream meet (weichiu: rev 0e28cd8f63615dddded2f1183f27efb5c2aaf6aa)* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/CannotObtainBlockLengthException.java* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,DataStreamer#createBlockOutputStream() should log exception in warn.,HDFS-15045,13273561,,Bug,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Major,Fixed,Sushma_28,surendrasingh,surendrasingh,10/12/2019 09:08,11/12/2019 03:39,18/01/2020 01:03,11/12/2019 03:27,3.1.1,,,,,3.3.0,,,,,,,dfsclient,,,,,,0,,,"{code:java}} catch (IOException ie) {        if (!errorState.isRestartingNode()) {          LOG.info(""Exception in createBlockOutputStream "" + this, ie);        } {code}",,elgoiri,hudson,surendrasingh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10/Dec/19 14:57;Sushma_28;HDFS-15045.001.patch;https://issues.apache.org/jira/secure/attachment/12988433/HDFS-15045.001.patch,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,23:44.5,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Wed Dec 11 03:39:36 UTC 2019,,,,,,0|z09ifk:,9.22337E+18,,,,,,,,,,,,,,,,,,"10/Dec/19 09:14;surendrasingh;Some time client side only warn log will be enabled, so user will not be able to get the reson for pipline failure..{code:java}2019-12-09 21:33:50,214 INFO hdfs.DataStreamer: Exception in createBlockOutputStream blk_1088983977_15246062java.net.BindException: Cannot assign requested address at sun.nio.ch.Net.connect0(Native Method) at sun.nio.ch.Net.connect(Net.java:454) at sun.nio.ch.Net.connect(Net.java:446) at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648) at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192) at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) at org.apache.hadoop.hdfs.DataStreamer.createSocketForPipeline(DataStreamer.java:255) at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1789) at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1743) at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:718){code}","10/Dec/19 18:21;surendrasingh;+1, will wait for build.","10/Dec/19 19:23;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 42s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 22m 17s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 25s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  3m  5s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 12s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 29s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 41s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m  5s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 21s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 29s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m  3s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black} 53m  0s{color} | {color:black} {color} |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:104ccca9169 || JIRA Issue | HDFS-15045 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12988433/HDFS-15045.001.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux cb6472647629 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 875a3e9 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28494/testReport/ || Max. process+thread count | 307 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs-client U: hadoop-hdfs-project/hadoop-hdfs-client || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28494/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.","11/Dec/19 03:27;surendrasingh;Committed to trunk.Thanks [~Sushma_28]�� for contribution.","11/Dec/19 03:39;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17750 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17750/])HDFS-15045. DataStreamer#createBlockOutputStream() should log exception (surendralilhore: rev c2e9783d5f236015f2ad826fcbad061e2118e454)* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[Dynamometer] Show the line of audit log when parsing it unsuccessfully,HDFS-15044,13273542,13215847,Sub-task,Resolved,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Major,Fixed,tasanuma,tasanuma,tasanuma,10/12/2019 07:44,13/12/2019 00:28,18/01/2020 01:03,12/12/2019 15:51,,,,,,3.3.0,,,,,,,tools,,,,,,0,,,,,aajisaka,hudson,tasanuma,xkrogen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,51:00.0,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Fri Dec 13 00:28:39 UTC 2019,,,,,,0|z09ibc:,9.22337E+18,,,,,,,,,,,,,,,,,,12/Dec/19 15:51;xkrogen;Just committed this to trunk. Thanks for the contribution [~tasanuma]!,"12/Dec/19 16:05;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17757 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17757/])HDFS-15044. [Dynamometer] Show the line of audit log when parsing it (xkrogen: rev c210cede5ce143a0c12646d82d657863f0ec96b6)* (edit) hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-workload/src/main/java/org/apache/hadoop/tools/dynamometer/workloadgenerator/audit/AuditLogDirectParser.java","13/Dec/19 00:28;tasanuma;Thanks for reviewing and committing it, [~xkrogen]!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Correct target DN's log while balancing.,HDFS-15027,13271677,,Bug,Patch Available,HDFS,Hadoop HDFS,software,dhruba,Hadoop Distributed File System,https://hadoop.apache.org/,Minor,,xudongcao,xudongcao,xudongcao,02/12/2019 11:48,13/01/2020 01:53,18/01/2020 01:03,,3.2.1,,,,,,,,,,,,balancer & mover,,,,,02/12/2019 00:00,0,,,"During HDFS balancing, after the target DN copied a block from the proxy DN, it prints a log following the pattern below:*Moved BLOCK from BALANCER*This is wrong and misleading, maybe we can improve the pattern like:*Moved BLOCK complete, copied from PROXY DN, initiated by*��*BALANCER*��An example log of target DN during balancing:1. Wrong log printing before jira:{code:java}2019-12-04 09:33:19,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Moved BP-1426342230-192.168.202.11-1575277482603:blk_1073741889_1065 from /192.168.202.13:56322, delHint=54a14a41-0d7c-4487-b4f0-ce2848f86b48{code}2. Correct log printing after jira:{code:java}2019-12-12 10:06:34,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Moved BP-1360308441-192.168.202.11-1576116241828:blk_1073741872_1048 complete, copied from /192.168.202.11:9866, initiated by /192.168.202.13:53536, delHint=c70406f8-a815-4f6f-bdf0-fd3661bd6920{code}",,weichiu,xudongcao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,04/Dec/19 02:38;xudongcao;HDFS-15027.000.patch;https://issues.apache.org/jira/secure/attachment/12987421/HDFS-15027.000.patch,12/Dec/19 02:13;xudongcao;HDFS-15027.001.patch;https://issues.apache.org/jira/secure/attachment/12988628/HDFS-15027.001.patch,,,,,,,,,,,,,,,,,,,,,,,2,,,,,,,,,,,,,,,,,,,02:03.3,,,FALSE,,,,,,,,,,,,,,,,,9.22337E+18,,,,,Mon Jan 13 01:53:41 UTC 2020,,,,,,0|z096t4:,9.22337E+18,,,,,,,,,,,,,,,,,,"02/Dec/19 15:02;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 15s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 23m 17s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 19s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 28s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 52s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 35s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 22s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 13s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 18s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 38s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 50s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 20s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}106m 31s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 32s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}179m 54s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits ||   | hadoop.hdfs.TestDFSInotifyEventInputStreamKerberized ||   | hadoop.hdfs.server.namenode.TestNamenodeCapacityReport ||   | hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:104ccca9169 || JIRA Issue | HDFS-15027 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12987291/HDFS-15027.000.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux a9e9991bdc88 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 6b2d6d4 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28430/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28430/testReport/ || Max. process+thread count | 2994 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28430/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.","02/Dec/19 16:01;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 33s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  1s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m 53s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  8s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 16s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 44s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 32s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  7s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  7s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 14s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 12s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 45s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 28s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}106m 59s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}177m 25s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.TestDFSStorageStateRecovery ||   | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy ||   | hadoop.hdfs.TestErasureCodingPolicies ||   | hadoop.hdfs.TestDecommissionWithStriped ||   | hadoop.hdfs.TestDistributedFileSystemWithECFileWithRandomECPolicy ||   | hadoop.hdfs.TestDFSStripedOutputStream ||   | hadoop.hdfs.TestDistributedFileSystem ||   | hadoop.hdfs.TestReadStripedFileWithDNFailure ||   | hadoop.hdfs.server.balancer.TestBalancer ||   | hadoop.hdfs.security.TestDelegationTokenForProxyUser ||   | hadoop.hdfs.server.datanode.TestDataNodeUUID ||   | hadoop.hdfs.server.datanode.TestDataNodeMetrics ||   | hadoop.hdfs.TestFileAppend4 ||   | hadoop.hdfs.TestReadStripedFileWithDecoding ||   | hadoop.hdfs.TestFileChecksum ||   | hadoop.hdfs.TestDFSStripedOutputStreamWithRandomECPolicy |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:104ccca9169 || JIRA Issue | HDFS-15027 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12987293/HDFS-15027.000.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 7fdda56a13b2 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 6b2d6d4 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28431/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28431/testReport/ || Max. process+thread count | 3538 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28431/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",03/Dec/19 21:41;weichiu;Was the patch file deleted from the attachments?,"04/Dec/19 02:40;xudongcao;cc��[~weichiu]��Sorry, patch uploaded again, this is just a minor log improvement, I think there's no need for unit test.","04/Dec/19 05:50;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 59s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 23m 22s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 17s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 18s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 17m 50s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 13s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 10s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 23s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 19s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red} 97m 45s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}167m 12s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean ||   | hadoop.hdfs.TestEncryptionZonesWithKMS |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:104ccca9169 || JIRA Issue | HDFS-15027 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12987421/HDFS-15027.000.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 074700de44c3 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 54e7605 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28442/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28442/testReport/ || Max. process+thread count | 2928 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28442/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.","12/Dec/19 02:09;xudongcao;[~weichiu] Perhaps we should keep the keyword ""Moved"" to reflect the meaning of moving block during balance, just like :*Moved BLOCK complete, copied from PROXY DN, initiated by*��*BALANCER*","12/Dec/19 05:06;hadoopqa;| (x) *{color:red}-1 overall{color}* |\\\\|| Vote || Subsystem || Runtime || Comment ||| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 43s{color} | {color:blue} Docker mode activated. {color} ||| || || || {color:brown} Prechecks {color} ||| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} || {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} ||| || || || {color:brown} trunk Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 45s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 10s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 47s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 16s{color} | {color:green} trunk passed {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 52s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} || {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 31s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 1 extant Findbugs warnings. {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} ||| || || || {color:brown} Patch Compile Tests {color} ||| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} || {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 42s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} || {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 24s{color} | {color:green} the patch passed {color} || {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} ||| || || || {color:brown} Other Tests {color} ||| {color:red}-1{color} | {color:red} unit {color} | {color:red}102m  5s{color} | {color:red} hadoop-hdfs in the patch failed. {color} || {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} || {color:black}{color} | {color:black} {color} | {color:black}165m 22s{color} | {color:black} {color} |\\\\|| Reason || Tests ||| Failed junit tests | hadoop.hdfs.server.namenode.TestFsck |\\\\|| Subsystem || Report/Notes ||| Docker | Client=19.03.5 Server=19.03.5 Image:yetus/hadoop:e573ea49085 || JIRA Issue | HDFS-15027 || JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12988628/HDFS-15027.001.patch || Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  || uname | Linux 22fa40b3b210 4.15.0-66-generic #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux || Build tool | maven || Personality | /testptch/patchprocess/precommit/personality/provided.sh || git revision | trunk / 93bb368 || maven | version: Apache Maven 3.3.9 || Default Java | 1.8.0_222 || findbugs | v3.1.0-RC1 || findbugs | https://builds.apache.org/job/PreCommit-HDFS-Build/28512/artifact/out/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html || unit | https://builds.apache.org/job/PreCommit-HDFS-Build/28512/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt ||  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/28512/testReport/ || Max. process+thread count | 3077 (vs. ulimit of 5500) || modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs || Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/28512/console || Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |This message was automatically generated.",13/Jan/20 01:53;xudongcao;[~weichiu]��can this patch be merged now?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,